{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec57217b",
   "metadata": {},
   "source": [
    "# Search Engine for Medium Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ecd494",
   "metadata": {},
   "source": [
    "- **Tokenization**\n",
    "- **Word Co Occurence Matrix**\n",
    "- **Continouous Bag of Words (CBoW)**\n",
    "- **Word2Vec**\n",
    "- **Search Articles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "97b8ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "\n",
    "import nltk, re, string, contractions\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d202a6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>author</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://towardsdatascience.com/ensemble-method...</td>\n",
       "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
       "      <td>Understanding the key concepts of ensemble lea...</td>\n",
       "      <td>Joseph Rocca</td>\n",
       "      <td>20</td>\n",
       "      <td>This post was co-written with Baptiste Rocca.\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://towardsdatascience.com/understanding-a...</td>\n",
       "      <td>Understanding AUC - ROC Curve</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>Sarang Narkhede</td>\n",
       "      <td>5</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://towardsdatascience.com/how-to-work-wit...</td>\n",
       "      <td>How to work with object detection datasets in ...</td>\n",
       "      <td>A comprehensive guide to defining, loading, ex...</td>\n",
       "      <td>Eric Hofesmann</td>\n",
       "      <td>10</td>\n",
       "      <td>Microsoft's Common Objects in Context dataset ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://towardsdatascience.com/11-dimensionali...</td>\n",
       "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
       "      <td>Reduce the size of your dataset while keeping ...</td>\n",
       "      <td>Rukshan Pramoditha</td>\n",
       "      <td>16</td>\n",
       "      <td>In both Statistics and Machine Learning, the n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://towardsdatascience.com/the-time-series...</td>\n",
       "      <td>The Time Series Transformer</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>Theodoros Ntakouris</td>\n",
       "      <td>6</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://towardsdatascience.com/ensemble-method...   \n",
       "1  https://towardsdatascience.com/understanding-a...   \n",
       "2  https://towardsdatascience.com/how-to-work-wit...   \n",
       "3  https://towardsdatascience.com/11-dimensionali...   \n",
       "4  https://towardsdatascience.com/the-time-series...   \n",
       "\n",
       "                                               title  \\\n",
       "0   Ensemble methods: bagging, boosting and stacking   \n",
       "1                      Understanding AUC - ROC Curve   \n",
       "2  How to work with object detection datasets in ...   \n",
       "3  11 Dimensionality reduction techniques you sho...   \n",
       "4                        The Time Series Transformer   \n",
       "\n",
       "                                           sub_title               author  \\\n",
       "0  Understanding the key concepts of ensemble lea...         Joseph Rocca   \n",
       "1  In Machine Learning, performance measurement i...      Sarang Narkhede   \n",
       "2  A comprehensive guide to defining, loading, ex...       Eric Hofesmann   \n",
       "3  Reduce the size of your dataset while keeping ...   Rukshan Pramoditha   \n",
       "4  Attention Is All You Need they said. Is it a m...  Theodoros Ntakouris   \n",
       "\n",
       "   reading_time                                               text  id  \n",
       "0            20  This post was co-written with Baptiste Rocca.\\...   1  \n",
       "1             5  In Machine Learning, performance measurement i...   2  \n",
       "2            10  Microsoft's Common Objects in Context dataset ...   3  \n",
       "3            16  In both Statistics and Machine Learning, the n...   4  \n",
       "4             6  Attention Is All You Need they said. Is it a m...   5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(r'F:\\Muthu_2023\\Personal\\NextStep\\NLP\\NLP\\Dataset\\medium_articles_v3.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9e7b72",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74bd014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(text):\n",
    "    sent_tokens = sent_tokenize(text)\n",
    "    stop_words = stopwords.words('English')\n",
    "    sent_processed = []\n",
    "    for sent in sent_tokens:\n",
    "        sent = re.sub(r'[^a-zA-Z0-9 ]',' ', contractions.fix(sent.lower()))\n",
    "        word_list = []\n",
    "        for word in sent.split():\n",
    "            if word not in stop_words and len(word.strip()) > 1:\n",
    "                word_list.append(word)\n",
    "        if len(word_list)>0:\n",
    "            sent_processed.append(' '.join(word_list))\n",
    "    return(sent_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aa70a0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>author</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://towardsdatascience.com/ensemble-method...</td>\n",
       "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
       "      <td>Understanding the key concepts of ensemble lea...</td>\n",
       "      <td>Joseph Rocca</td>\n",
       "      <td>20</td>\n",
       "      <td>This post was co-written with Baptiste Rocca.\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>[post co written baptiste rocca, unity strengt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://towardsdatascience.com/understanding-a...</td>\n",
       "      <td>Understanding AUC - ROC Curve</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>Sarang Narkhede</td>\n",
       "      <td>5</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>2</td>\n",
       "      <td>[machine learning performance measurement esse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://towardsdatascience.com/how-to-work-wit...</td>\n",
       "      <td>How to work with object detection datasets in ...</td>\n",
       "      <td>A comprehensive guide to defining, loading, ex...</td>\n",
       "      <td>Eric Hofesmann</td>\n",
       "      <td>10</td>\n",
       "      <td>Microsoft's Common Objects in Context dataset ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[microsoft common objects context dataset coco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://towardsdatascience.com/11-dimensionali...</td>\n",
       "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
       "      <td>Reduce the size of your dataset while keeping ...</td>\n",
       "      <td>Rukshan Pramoditha</td>\n",
       "      <td>16</td>\n",
       "      <td>In both Statistics and Machine Learning, the n...</td>\n",
       "      <td>4</td>\n",
       "      <td>[statistics machine learning number attributes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://towardsdatascience.com/the-time-series...</td>\n",
       "      <td>The Time Series Transformer</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>Theodoros Ntakouris</td>\n",
       "      <td>6</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>5</td>\n",
       "      <td>[attention need said, robust convolution, hack...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://towardsdatascience.com/ensemble-method...   \n",
       "1  https://towardsdatascience.com/understanding-a...   \n",
       "2  https://towardsdatascience.com/how-to-work-wit...   \n",
       "3  https://towardsdatascience.com/11-dimensionali...   \n",
       "4  https://towardsdatascience.com/the-time-series...   \n",
       "\n",
       "                                               title  \\\n",
       "0   Ensemble methods: bagging, boosting and stacking   \n",
       "1                      Understanding AUC - ROC Curve   \n",
       "2  How to work with object detection datasets in ...   \n",
       "3  11 Dimensionality reduction techniques you sho...   \n",
       "4                        The Time Series Transformer   \n",
       "\n",
       "                                           sub_title               author  \\\n",
       "0  Understanding the key concepts of ensemble lea...         Joseph Rocca   \n",
       "1  In Machine Learning, performance measurement i...      Sarang Narkhede   \n",
       "2  A comprehensive guide to defining, loading, ex...       Eric Hofesmann   \n",
       "3  Reduce the size of your dataset while keeping ...   Rukshan Pramoditha   \n",
       "4  Attention Is All You Need they said. Is it a m...  Theodoros Ntakouris   \n",
       "\n",
       "   reading_time                                               text  id  \\\n",
       "0            20  This post was co-written with Baptiste Rocca.\\...   1   \n",
       "1             5  In Machine Learning, performance measurement i...   2   \n",
       "2            10  Microsoft's Common Objects in Context dataset ...   3   \n",
       "3            16  In both Statistics and Machine Learning, the n...   4   \n",
       "4             6  Attention Is All You Need they said. Is it a m...   5   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  [post co written baptiste rocca, unity strengt...  \n",
       "1  [machine learning performance measurement esse...  \n",
       "2  [microsoft common objects context dataset coco...  \n",
       "3  [statistics machine learning number attributes...  \n",
       "4  [attention need said, robust convolution, hack...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['transformed_text'] = raw_data['text'].apply(text_preprocess)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8294799",
   "metadata": {},
   "source": [
    "## Word Co Occurence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aa45ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list = raw_data['transformed_text'].explode()\n",
    "voc_list = sent_list.str.split().explode().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e0e41d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30968"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9c4d5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list = raw_data['transformed_text'].explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "292e47cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26892"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5d35d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for sentence in sent_list:\n",
    "    words = sentence.split()\n",
    "    for i in range(len(words)-1):\n",
    "        if (words[i], words[i+1]) not in d and (words[i+1], words[i]) not in d:\n",
    "            d[(words[i], words[i+1])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "737174ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('Muthu', 'kumar1') in d:\n",
    "    print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1827541e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190509"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "45c8429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame()\n",
    "temp_df['sentences'] = raw_data['transformed_text'].explode().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e682b8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[post, co, written, baptiste, rocca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[unity, strength]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[old, saying, expresses, pretty, well, underly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[roughly, ensemble, learning, methods, often, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[purpose, post, introduce, various, notions, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>[cannot, eat, way, every, day, month, stay, ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>[written, week, week, guide, eating, accordanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>[bottom, line, use, menstrual, cycle, lose, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>[created, quick, start, guide, including, meal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>[liked, article, click, share, others, enjoy, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26892 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentences\n",
       "0                 [post, co, written, baptiste, rocca]\n",
       "0                                    [unity, strength]\n",
       "0    [old, saying, expresses, pretty, well, underly...\n",
       "0    [roughly, ensemble, learning, methods, often, ...\n",
       "0    [purpose, post, introduce, various, notions, e...\n",
       "..                                                 ...\n",
       "207  [cannot, eat, way, every, day, month, stay, ke...\n",
       "207  [written, week, week, guide, eating, accordanc...\n",
       "207  [bottom, line, use, menstrual, cycle, lose, we...\n",
       "207  [created, quick, start, guide, including, meal...\n",
       "207  [liked, article, click, share, others, enjoy, ...\n",
       "\n",
       "[26892 rows x 1 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9fdcced7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:441\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m factorize(values, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:822\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, na_sentinel, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    820\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 822\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m factorize_array(\n\u001b[0;32m    823\u001b[0m         values,\n\u001b[0;32m    824\u001b[0m         na_sentinel\u001b[38;5;241m=\u001b[39mna_sentinel_arg,\n\u001b[0;32m    825\u001b[0m         size_hint\u001b[38;5;241m=\u001b[39msize_hint,\n\u001b[0;32m    826\u001b[0m     )\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:578\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    577\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 578\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfactorize(\n\u001b[0;32m    579\u001b[0m     values,\n\u001b[0;32m    580\u001b[0m     na_sentinel\u001b[38;5;241m=\u001b[39mna_sentinel,\n\u001b[0;32m    581\u001b[0m     na_value\u001b[38;5;241m=\u001b[39mna_value,\n\u001b[0;32m    582\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    583\u001b[0m     ignore_na\u001b[38;5;241m=\u001b[39mignore_na,\n\u001b[0;32m    584\u001b[0m )\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5943\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5857\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mget_dummies(temp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:204\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    202\u001b[0m     result \u001b[38;5;241m=\u001b[39m concat(with_dummies, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m     result \u001b[38;5;241m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    205\u001b[0m         data,\n\u001b[0;32m    206\u001b[0m         prefix,\n\u001b[0;32m    207\u001b[0m         prefix_sep,\n\u001b[0;32m    208\u001b[0m         dummy_na,\n\u001b[0;32m    209\u001b[0m         sparse\u001b[38;5;241m=\u001b[39msparse,\n\u001b[0;32m    210\u001b[0m         drop_first\u001b[38;5;241m=\u001b[39mdrop_first,\n\u001b[0;32m    211\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    212\u001b[0m     )\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:228\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Series avoids inconsistent NaN handling\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m codes, levels \u001b[38;5;241m=\u001b[39m factorize_from_iterable(Series(data))\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:2980\u001b[0m, in \u001b[0;36mfactorize_from_iterable\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   2975\u001b[0m     codes \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcodes\n\u001b[0;32m   2976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2977\u001b[0m     \u001b[38;5;66;03m# The value of ordered is irrelevant since we don't use cat as such,\u001b[39;00m\n\u001b[0;32m   2978\u001b[0m     \u001b[38;5;66;03m# but only the resulting categories, the order of which is independent\u001b[39;00m\n\u001b[0;32m   2979\u001b[0m     \u001b[38;5;66;03m# from ordered. Set ordered to False as default. See GH #15457\u001b[39;00m\n\u001b[1;32m-> 2980\u001b[0m     cat \u001b[38;5;241m=\u001b[39m Categorical(values, ordered\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2981\u001b[0m     categories \u001b[38;5;241m=\u001b[39m cat\u001b[38;5;241m.\u001b[39mcategories\n\u001b[0;32m   2982\u001b[0m     codes \u001b[38;5;241m=\u001b[39m cat\u001b[38;5;241m.\u001b[39mcodes\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:443\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[0;32m    441\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m factorize(values, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 443\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m factorize(values, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mordered:\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;66;03m# raise, as we don't have a sortable data structure and so\u001b[39;00m\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;66;03m# the user should give us one by specifying categories\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    448\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not ordered, please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplicitly specify the categories order \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby passing in a categories argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:822\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, na_sentinel, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    820\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 822\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m factorize_array(\n\u001b[0;32m    823\u001b[0m         values,\n\u001b[0;32m    824\u001b[0m         na_sentinel\u001b[38;5;241m=\u001b[39mna_sentinel_arg,\n\u001b[0;32m    825\u001b[0m         size_hint\u001b[38;5;241m=\u001b[39msize_hint,\n\u001b[0;32m    826\u001b[0m     )\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m na_sentinel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    830\u001b[0m         \u001b[38;5;66;03m# TODO: Can remove when na_sentinel=na_sentinel as in TODO above\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:578\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    575\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    577\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 578\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfactorize(\n\u001b[0;32m    579\u001b[0m     values,\n\u001b[0;32m    580\u001b[0m     na_sentinel\u001b[38;5;241m=\u001b[39mna_sentinel,\n\u001b[0;32m    581\u001b[0m     na_value\u001b[38;5;241m=\u001b[39mna_value,\n\u001b[0;32m    582\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    583\u001b[0m     ignore_na\u001b[38;5;241m=\u001b[39mignore_na,\n\u001b[0;32m    584\u001b[0m )\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[0;32m    587\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5943\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5857\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "pd.get_dummies(temp_df['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6bbdc1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   S_  column1_a  column1_c  column1_d  column2_a  column2_c  column2_d\n",
      "0   1          1          0          0          0          0          1\n",
      "1   2          0          1          0          1          0          0\n",
      "2   3          0          0          1          0          1          0\n"
     ]
    }
   ],
   "source": [
    "diff = pd.DataFrame({'R': ['a', 'c', 'd'], \n",
    "                     'T': ['d', 'a', 'c'],\n",
    "                     'S_': [1, 2, 3]})\n",
    " \n",
    "print(pd.get_dummies(diff, prefix=['column1', 'column2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "26a8ce48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>T</th>\n",
       "      <th>S_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R  T  S_\n",
       "0  a  d   1\n",
       "1  c  a   2\n",
       "2  d  c   3"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf6215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
