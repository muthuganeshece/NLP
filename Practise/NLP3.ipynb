{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbd71534",
   "metadata": {},
   "source": [
    "# Search Engine for Medium Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbf54fd",
   "metadata": {},
   "source": [
    "- **Tokenization**\n",
    "- **Word Co Occurence Matrix**\n",
    "- **Continouous Bag of Words (CBoW)**\n",
    "- **Word2Vec**\n",
    "- **Search Articles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697a1d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "\n",
    "import nltk, re, string, contractions\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c24e62e0-59c7-4ce2-aa78-71edd658448d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Muthukumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d202a6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>author</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://towardsdatascience.com/ensemble-method...</td>\n",
       "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
       "      <td>Understanding the key concepts of ensemble lea...</td>\n",
       "      <td>Joseph Rocca</td>\n",
       "      <td>20</td>\n",
       "      <td>This post was co-written with Baptiste Rocca.\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://towardsdatascience.com/understanding-a...</td>\n",
       "      <td>Understanding AUC - ROC Curve</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>Sarang Narkhede</td>\n",
       "      <td>5</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://towardsdatascience.com/how-to-work-wit...</td>\n",
       "      <td>How to work with object detection datasets in ...</td>\n",
       "      <td>A comprehensive guide to defining, loading, ex...</td>\n",
       "      <td>Eric Hofesmann</td>\n",
       "      <td>10</td>\n",
       "      <td>Microsoft's Common Objects in Context dataset ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://towardsdatascience.com/11-dimensionali...</td>\n",
       "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
       "      <td>Reduce the size of your dataset while keeping ...</td>\n",
       "      <td>Rukshan Pramoditha</td>\n",
       "      <td>16</td>\n",
       "      <td>In both Statistics and Machine Learning, the n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://towardsdatascience.com/the-time-series...</td>\n",
       "      <td>The Time Series Transformer</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>Theodoros Ntakouris</td>\n",
       "      <td>6</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://towardsdatascience.com/ensemble-method...   \n",
       "1  https://towardsdatascience.com/understanding-a...   \n",
       "2  https://towardsdatascience.com/how-to-work-wit...   \n",
       "3  https://towardsdatascience.com/11-dimensionali...   \n",
       "4  https://towardsdatascience.com/the-time-series...   \n",
       "\n",
       "                                               title  \\\n",
       "0   Ensemble methods: bagging, boosting and stacking   \n",
       "1                      Understanding AUC - ROC Curve   \n",
       "2  How to work with object detection datasets in ...   \n",
       "3  11 Dimensionality reduction techniques you sho...   \n",
       "4                        The Time Series Transformer   \n",
       "\n",
       "                                           sub_title               author  \\\n",
       "0  Understanding the key concepts of ensemble lea...         Joseph Rocca   \n",
       "1  In Machine Learning, performance measurement i...      Sarang Narkhede   \n",
       "2  A comprehensive guide to defining, loading, ex...       Eric Hofesmann   \n",
       "3  Reduce the size of your dataset while keeping ...   Rukshan Pramoditha   \n",
       "4  Attention Is All You Need they said. Is it a m...  Theodoros Ntakouris   \n",
       "\n",
       "   reading_time                                               text  id  \n",
       "0            20  This post was co-written with Baptiste Rocca.\\...   1  \n",
       "1             5  In Machine Learning, performance measurement i...   2  \n",
       "2            10  Microsoft's Common Objects in Context dataset ...   3  \n",
       "3            16  In both Statistics and Machine Learning, the n...   4  \n",
       "4             6  Attention Is All You Need they said. Is it a m...   5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raw_data = pd.read_csv(r'F:\\Muthu_2023\\Personal\\NextStep\\NLP\\NLP\\Dataset\\medium_articles_v3.csv')\n",
    "raw_data = pd.read_csv(r'E:\\Nextstep\\NLP\\Dataset\\medium_articles_v3.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0281add",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.drop(66)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6026ebc",
   "metadata": {},
   "source": [
    "`As per Analysis, Article 67 contains 10000+ unique words due to the presence of names of google scholars`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3541dcf",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f445b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(text):\n",
    "    sent_tokens = sent_tokenize(text)\n",
    "    stop_words = stopwords.words('English')\n",
    "    sent_processed = []\n",
    "    for sent in sent_tokens:\n",
    "        sent = re.sub(r'[^a-zA-Z0-9 ]',' ', contractions.fix(sent.lower()))\n",
    "        sent = re.sub(r'https://[^\\s\\n\\r]+', '', sent) #Remove links\n",
    "        sent = re.sub(r'http://[^\\s\\n\\r]+', '', sent)\n",
    "        sent = re.sub(r'[^a-zA-Z0-9 ]',' ', sent)\n",
    "        word_list = []\n",
    "        for word in sent.split():\n",
    "            if word not in stop_words and len(word.strip()) > 1 and not word.isnumeric() and not bool(re.search(r'\\d', word)) and len(word.strip()) < 20:\n",
    "                word_list.append(word)\n",
    "        if len(word_list)>0:\n",
    "            sent_processed.append(' '.join(word_list))\n",
    "    return(sent_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bf2490c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>author</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://towardsdatascience.com/ensemble-method...</td>\n",
       "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
       "      <td>Understanding the key concepts of ensemble lea...</td>\n",
       "      <td>Joseph Rocca</td>\n",
       "      <td>20</td>\n",
       "      <td>This post was co-written with Baptiste Rocca.\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>[post co written baptiste rocca, unity strengt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://towardsdatascience.com/understanding-a...</td>\n",
       "      <td>Understanding AUC - ROC Curve</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>Sarang Narkhede</td>\n",
       "      <td>5</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>2</td>\n",
       "      <td>[machine learning performance measurement esse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://towardsdatascience.com/how-to-work-wit...</td>\n",
       "      <td>How to work with object detection datasets in ...</td>\n",
       "      <td>A comprehensive guide to defining, loading, ex...</td>\n",
       "      <td>Eric Hofesmann</td>\n",
       "      <td>10</td>\n",
       "      <td>Microsoft's Common Objects in Context dataset ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[microsoft common objects context dataset coco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://towardsdatascience.com/11-dimensionali...</td>\n",
       "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
       "      <td>Reduce the size of your dataset while keeping ...</td>\n",
       "      <td>Rukshan Pramoditha</td>\n",
       "      <td>16</td>\n",
       "      <td>In both Statistics and Machine Learning, the n...</td>\n",
       "      <td>4</td>\n",
       "      <td>[statistics machine learning number attributes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://towardsdatascience.com/the-time-series...</td>\n",
       "      <td>The Time Series Transformer</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>Theodoros Ntakouris</td>\n",
       "      <td>6</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>5</td>\n",
       "      <td>[attention need said, robust convolution, hack...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://towardsdatascience.com/ensemble-method...   \n",
       "1  https://towardsdatascience.com/understanding-a...   \n",
       "2  https://towardsdatascience.com/how-to-work-wit...   \n",
       "3  https://towardsdatascience.com/11-dimensionali...   \n",
       "4  https://towardsdatascience.com/the-time-series...   \n",
       "\n",
       "                                               title  \\\n",
       "0   Ensemble methods: bagging, boosting and stacking   \n",
       "1                      Understanding AUC - ROC Curve   \n",
       "2  How to work with object detection datasets in ...   \n",
       "3  11 Dimensionality reduction techniques you sho...   \n",
       "4                        The Time Series Transformer   \n",
       "\n",
       "                                           sub_title               author  \\\n",
       "0  Understanding the key concepts of ensemble lea...         Joseph Rocca   \n",
       "1  In Machine Learning, performance measurement i...      Sarang Narkhede   \n",
       "2  A comprehensive guide to defining, loading, ex...       Eric Hofesmann   \n",
       "3  Reduce the size of your dataset while keeping ...   Rukshan Pramoditha   \n",
       "4  Attention Is All You Need they said. Is it a m...  Theodoros Ntakouris   \n",
       "\n",
       "   reading_time                                               text  id  \\\n",
       "0            20  This post was co-written with Baptiste Rocca.\\...   1   \n",
       "1             5  In Machine Learning, performance measurement i...   2   \n",
       "2            10  Microsoft's Common Objects in Context dataset ...   3   \n",
       "3            16  In both Statistics and Machine Learning, the n...   4   \n",
       "4             6  Attention Is All You Need they said. Is it a m...   5   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  [post co written baptiste rocca, unity strengt...  \n",
       "1  [machine learning performance measurement esse...  \n",
       "2  [microsoft common objects context dataset coco...  \n",
       "3  [statistics machine learning number attributes...  \n",
       "4  [attention need said, robust convolution, hack...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['transformed_text'] = raw_data['text'].apply(text_preprocess)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a025fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 207 entries, 0 to 207\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   link              207 non-null    object\n",
      " 1   title             207 non-null    object\n",
      " 2   sub_title         207 non-null    object\n",
      " 3   author            207 non-null    object\n",
      " 4   reading_time      207 non-null    int64 \n",
      " 5   text              207 non-null    object\n",
      " 6   id                207 non-null    int64 \n",
      " 7   transformed_text  207 non-null    object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 14.6+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c209e817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4634467",
   "metadata": {},
   "source": [
    "## Word Co Occurence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9abe2ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  19511 No. of sentences:  26534\n"
     ]
    }
   ],
   "source": [
    "sent_list = raw_data['transformed_text'].explode()\n",
    "voc_list = sent_list.str.split().explode().unique()\n",
    "print('Vocabulary Size: ', len(voc_list), 'No. of sentences: ', len(sent_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bb9ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for sentence in sent_list:\n",
    "    words = sentence.split()\n",
    "    for i in range(len(words)-2):\n",
    "        if (words[i], words[i+1]) not in d:\n",
    "            if (words[i+1], words[i]) not in d:\n",
    "                d[(words[i], words[i+1])] = 1\n",
    "            else:\n",
    "                d[(words[i+1], words[i])] += 1\n",
    "        else:\n",
    "            d[(words[i], words[i+1])] += 1\n",
    "            \n",
    "        if (words[i], words[i+2]) not in d:\n",
    "            if (words[i+2], words[i]) not in d:\n",
    "                d[(words[i], words[i+2])] = 1\n",
    "            else:\n",
    "                d[(words[i+2], words[i])] += 1\n",
    "        else:\n",
    "            d[(words[i], words[i+2])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59964ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "for sentence in sent_list:\n",
    "    words = sentence.split()\n",
    "    for ind in range(len(words)):\n",
    "        pair_list = []\n",
    "        for sub_ind in range(ind - 2, ind + 3):\n",
    "            if sub_ind != ind and sub_ind >= 0 and sub_ind < len(words):\n",
    "                pair_list.append(words[sub_ind])                \n",
    "        if len(pair_list) > 0:\n",
    "            x_list.append(pair_list)\n",
    "            y_list.append([words[ind]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ae3b7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244928, 244928)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_list), len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38379508",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes = voc_list, sparse_output=True) # Generates Multi label Encoding with sparse output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a37fca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = mlb.fit_transform(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0864538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = mlb.fit_transform(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e2fc636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['post', 'co', 'written', ..., 'serotonin', 'gobbled', 'critic'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0b2bd",
   "metadata": {},
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6a1c3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b783c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3327da8d-4e3f-4540-8c3f-c7a24f645bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9918b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = 10\n",
    "voc_size = len(voc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b413e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(voc_size,), sparse=True))\n",
    "model.add(Dense(vec_size, activation='relu'))\n",
    "model.add(Dense(voc_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2ec337b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='SparseCategoricalCrossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d262907b-b1ac-410d-9f55-0476064bbb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eedd0439-1b3c-4a3a-9ea9-1f5a35d9ba18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(indices=tf.Tensor(\n",
       "[[     0      0]\n",
       " [     1      1]\n",
       " [     2      2]\n",
       " ...\n",
       " [244925     62]\n",
       " [244926   1479]\n",
       " [244927     11]], shape=(244928, 2), dtype=int64), values=tf.Tensor([1 1 1 ... 1 1 1], shape=(244928,), dtype=int32), dense_shape=tf.Tensor([244928  19511], shape=(2,), dtype=int64))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_sparse_matrix_to_sparse_tensor(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3236b444",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__SerializeManySparse_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[20] = [8,7] is out of order. Many sparse ops require sorted indices.\n    Use `tf.sparse.reorder` to create a correctly ordered copy.\n\n [Op:SerializeManySparse]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(convert_sparse_matrix_to_sparse_tensor(xtrain), convert_sparse_matrix_to_sparse_tensor(ytrain), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7261\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7262\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__SerializeManySparse_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[20] = [8,7] is out of order. Many sparse ops require sorted indices.\n    Use `tf.sparse.reorder` to create a correctly ordered copy.\n\n [Op:SerializeManySparse]"
     ]
    }
   ],
   "source": [
    "model.fit(convert_sparse_matrix_to_sparse_tensor(xtrain), convert_sparse_matrix_to_sparse_tensor(ytrain), epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2fda0965",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect\n",
    "we conjure the spirits of the computer with our spells.\"\"\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7b5d3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sentences.split()\n",
    "vocab = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9d1ee46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(2, len(words) - 2):\n",
    "    context = [words[i - 2], words[i - 1], words[i + 1], words[i + 2]]\n",
    "    target = words[i]\n",
    "    data.append((context, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "68d648d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input must be a SparseTensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[263], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tf\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mreorder(xtrain)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py:847\u001b[0m, in \u001b[0;36msparse_reorder\u001b[1;34m(sp_input, name)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse.reorder\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse.reorder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_reorder\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    811\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated_endpoints(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_reorder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msparse_reorder\u001b[39m(sp_input, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    813\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reorders a `SparseTensor` into the canonical, row-major ordering.\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \n\u001b[0;32m    815\u001b[0m \u001b[38;5;124;03m  Note that by convention, all sparse ops preserve the canonical ordering\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;124;03m    TypeError: If `sp_input` is not a `SparseTensor`.\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 847\u001b[0m   sp_input \u001b[38;5;241m=\u001b[39m _convert_to_sparse_tensor(sp_input)\n\u001b[0;32m    849\u001b[0m   reordered_ind, reordered_val \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    850\u001b[0m       gen_sparse_ops\u001b[38;5;241m.\u001b[39msparse_reorder(\n\u001b[0;32m    851\u001b[0m           sp_input\u001b[38;5;241m.\u001b[39mindices, sp_input\u001b[38;5;241m.\u001b[39mvalues, sp_input\u001b[38;5;241m.\u001b[39mdense_shape, name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    853\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m sp_input\u001b[38;5;241m.\u001b[39mget_shape()\u001b[38;5;241m.\u001b[39mis_fully_defined():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py:67\u001b[0m, in \u001b[0;36m_convert_to_sparse_tensor\u001b[1;34m(sp_input)\u001b[0m\n\u001b[0;32m     65\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m sparse_tensor\u001b[38;5;241m.\u001b[39mSparseTensor\u001b[38;5;241m.\u001b[39mfrom_value(sp_input)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sp_input, sparse_tensor\u001b[38;5;241m.\u001b[39mSparseTensor):\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a SparseTensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sp_input\n",
      "\u001b[1;31mTypeError\u001b[0m: Input must be a SparseTensor."
     ]
    }
   ],
   "source": [
    "tf.sparse.reorder(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "621a4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8bf5141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_ = csr_matrix.sorted_indices(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f4df22c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<244928x19511 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 818906 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15bdbb0",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "300d3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea1e1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate list of list\n",
    "sentence_list = []\n",
    "for sent in sent_list:\n",
    "    word_list = []\n",
    "    for word in sent.split():\n",
    "        word_list.append(word)\n",
    "    sentence_list.append(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74be619a-3660-42bf-9129-27a52cafeb63",
   "metadata": {},
   "source": [
    "## CBoW using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be32798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentence_list, window=2, vector_size=100, sg=0, min_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "9e0dae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build_vocab(sentence_list, progress_per=10000)\n",
    "# model.train(sentence_list, total_examples=model.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e041eb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vending', 0.9217960834503174),\n",
       " ('translation', 0.8929186463356018),\n",
       " ('washing', 0.8903473615646362),\n",
       " ('repair', 0.8423986434936523),\n",
       " ('earliest', 0.8414889574050903),\n",
       " ('slot', 0.8408620953559875),\n",
       " ('envelopes', 0.8398900032043457),\n",
       " ('capsules', 0.8373095989227295),\n",
       " ('volunteered', 0.834150493144989),\n",
       " ('mastercard', 0.8338434100151062)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"learning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d652e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0237862 , -0.38215688, -0.05556021,  0.39030933,  0.26835766,\n",
       "       -0.9685569 ,  1.1269547 ,  0.52827674, -0.67589307, -0.10392741,\n",
       "        0.49126264, -0.1965297 , -0.37685892,  1.7085149 , -0.33567706,\n",
       "       -0.59292144,  1.4235001 ,  0.5721935 , -0.15958312, -2.5173852 ,\n",
       "        0.8205378 , -0.2597604 ,  1.7086773 , -0.3014652 , -0.41533405,\n",
       "        0.42606047, -0.4873449 , -0.50534207, -0.03519989, -0.40178236,\n",
       "        1.7446532 ,  1.5876681 , -0.11230429,  0.49677545, -1.1850039 ,\n",
       "        0.61231095, -1.5197169 , -1.6955729 , -1.3053275 , -2.140613  ,\n",
       "        0.86405545, -1.0840689 ,  0.9455743 , -1.2610888 ,  0.11255067,\n",
       "        0.91128683, -1.0392733 , -1.7087599 , -0.18029949,  0.3970201 ,\n",
       "        0.02042915, -1.580043  , -0.9794143 ,  0.09938424, -1.7822664 ,\n",
       "       -0.83774525, -0.60228837, -1.6656373 , -1.8647523 , -1.2973278 ,\n",
       "       -0.09623057, -0.44136506,  0.49341574,  0.07339007, -0.8351086 ,\n",
       "        1.2139884 , -0.3670534 , -0.42476758, -1.1924977 , -0.4767573 ,\n",
       "       -0.07439489,  0.9740269 , -0.57564634,  0.6969304 ,  1.2859291 ,\n",
       "       -1.0374676 ,  0.67612004,  0.67106307, -0.14112842,  1.2308666 ,\n",
       "        0.9632528 , -0.19892046, -1.4245051 ,  0.6007827 , -0.14726451,\n",
       "       -1.2293389 ,  1.8038964 , -0.00761095, -0.33572933,  0.3605267 ,\n",
       "        0.4664437 , -0.05839916, -0.44769967, -0.32844216,  0.505694  ,\n",
       "        0.48499405,  1.2959687 , -1.329115  ,  0.5853634 ,  0.97204596],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1c055a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muthukumar\\AppData\\Local\\Temp\\ipykernel_28544\\728846989.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_data['Centroid_cbow'].iloc[index] = centroid.tolist()\n"
     ]
    }
   ],
   "source": [
    "# Find Centroid\n",
    "raw_data['Centroid_cbow'] = [[0.0] * 100] * raw_data.shape[0]\n",
    "for index in range(len(raw_data)):\n",
    "    centroid = np.array([0.0] * 100)\n",
    "    article = raw_data['transformed_text'].iloc[index]\n",
    "    for sent in article:\n",
    "        for word in sent.split():\n",
    "            try:\n",
    "                centroid = np.add(centroid, model.wv[word])\n",
    "            except:\n",
    "                continue\n",
    "    raw_data['Centroid_cbow'].iloc[index] = centroid.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3510959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_article(query, df, model, col_name):\n",
    "    cos_sim_list = []\n",
    "    for index in range(len(df)):\n",
    "        cent_article = np.array(df[col_name].iloc[index]).reshape(1,-1)\n",
    "        cos_sim = 0\n",
    "        for word in query.split():\n",
    "            try:\n",
    "                temp_cent = np.array(model.wv[word]).reshape(1,-1)\n",
    "                cos_sim += (cosine_similarity(temp_cent, cent_article))\n",
    "            except:\n",
    "                continue\n",
    "        cos_sim_list.append([df['title'].iloc[index], cos_sim[0,0]])\n",
    "    return cos_sim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd18a1ba-bf47-4f1f-af51-48efd4787d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18    17 Clustering Algorithms Used In Data Science ...\n",
       "3     11 Dimensionality reduction techniques you sho...\n",
       "52    TRAIN A CUSTOM YOLOv4 OBJECT DETECTOR (Using G...\n",
       "19    Introduction to Genetic Algorithms  Including ...\n",
       "74    The 5 Clustering Algorithms Data Scientists Ne...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_articles = get_similar_article(\"principal component analysis\", raw_data, model, 'Centroid_cbow')\n",
    "temp_df = pd.DataFrame(similar_articles, columns=['title', 'score'])\n",
    "temp_df.sort_values('score', ascending=False)['title'].iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3fd9c4-913f-43f9-9537-ae79e03e6247",
   "metadata": {},
   "source": [
    "## Skipgram using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "53647935-fd61-4510-8ee0-ee19a7140d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sg = Word2Vec(sentence_list, min_count=0, window=2, vector_size=100, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8a4ec1e-93cc-4af3-961c-95042df24bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4514971 , -0.06575663, -0.04660844,  0.05198604,  0.11167115,\n",
       "       -0.33453867,  0.45436785,  0.08417453, -0.37928718,  0.00169973,\n",
       "        0.1480776 , -0.15703738, -0.14837955,  0.83874077, -0.13342898,\n",
       "       -0.38646498,  0.597749  ,  0.50272214, -0.1252687 , -0.97115844,\n",
       "        0.49803537, -0.11483087,  0.9821957 , -0.17528768, -0.22842406,\n",
       "        0.3397735 , -0.13709344, -0.5374775 , -0.12903762, -0.17602657,\n",
       "        1.0036551 ,  0.83098614, -0.01324456,  0.20545445, -0.4712755 ,\n",
       "        0.2481716 , -0.73464656, -0.727447  , -0.7408131 , -0.9686139 ,\n",
       "        0.34138075, -0.5425545 ,  0.38642862, -0.5712795 ,  0.03600386,\n",
       "        0.3683938 , -0.65368474, -0.88349015,  0.086861  ,  0.3330882 ,\n",
       "        0.09210204, -0.7773117 , -0.55614394,  0.00394889, -0.84166384,\n",
       "       -0.41658974, -0.25193766, -0.77118176, -0.9820485 , -0.56150347,\n",
       "       -0.01979044, -0.3817165 ,  0.05722544,  0.06648361, -0.3433137 ,\n",
       "        0.62319756, -0.20727728, -0.29181555, -0.5545251 , -0.11095647,\n",
       "       -0.1827145 ,  0.4046099 , -0.25723013,  0.36897883,  0.46952274,\n",
       "       -0.5169344 ,  0.25854707,  0.49446154, -0.05666538,  0.61810815,\n",
       "        0.3680099 , -0.2341235 , -0.8224055 ,  0.19652925, -0.0167584 ,\n",
       "       -0.4572373 ,  0.89801025, -0.2200404 , -0.07545637,  0.2666428 ,\n",
       "        0.08792894,  0.24304762, -0.20240892, -0.36219186,  0.10488766,\n",
       "        0.3142765 ,  0.54319715, -0.6016593 ,  0.29244438,  0.49024865],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.wv['learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "002d623d-1825-4914-888a-d21d9db754d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('translation', 0.8542159199714661),\n",
       " ('supervised', 0.8365312814712524),\n",
       " ('cpap', 0.8223248720169067),\n",
       " ('language', 0.8162795305252075),\n",
       " ('ai', 0.8143751621246338),\n",
       " ('geolocation', 0.8119624257087708),\n",
       " ('intelligence', 0.8092731833457947),\n",
       " ('brownlee', 0.8022918105125427),\n",
       " ('source', 0.802204430103302),\n",
       " ('python', 0.800692617893219)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.wv.most_similar(positive=['learning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9609e25c-26c4-4f02-9d7c-56c21bc63b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muthukumar\\AppData\\Local\\Temp\\ipykernel_28544\\244330531.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_data['Centroid_sg'].iloc[index] = centroid_article\n"
     ]
    }
   ],
   "source": [
    "raw_data['Centroid_sg'] = [[0.0] * 100 ] * raw_data.shape[0]\n",
    "for index in range(len(raw_data)):\n",
    "    text = raw_data['transformed_text'].iloc[index]\n",
    "    centroid_article = [0.0] * 100\n",
    "    for sent in text:\n",
    "        for word in sent.split():\n",
    "            try:\n",
    "                centroid_article = np.add(centroid_article, model_sg.wv[word])\n",
    "            except:\n",
    "                continue\n",
    "    raw_data['Centroid_sg'].iloc[index] = centroid_article    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cfbebcc7-fa89-46aa-b55d-eda6a04a4208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      11 Dimensionality reduction techniques you sho...\n",
       "44     How to Install Ubuntu Desktop With a Graphical...\n",
       "166          The Unexpected Case of the Disappearing Flu\n",
       "18     17 Clustering Algorithms Used In Data Science ...\n",
       "107    Public Mint Polkastarter IDO: Launching 23rd o...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df_sg = pd.DataFrame(get_similar_article('principle component analysis', raw_data, model_sg, 'Centroid_sg'), columns = ['title', 'score'])\n",
    "temp_df_sg.sort_values('score', ascending=False)['title'].iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6ebd5dac-ac08-42d2-9570-afc946254148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('classification', 0.9591761827468872),\n",
       " ('non', 0.9544885158538818),\n",
       " ('linear', 0.9541516900062561),\n",
       " ('clustering', 0.9520301222801208),\n",
       " ('methods', 0.9456323385238647),\n",
       " ('dimensionality', 0.9435859322547913),\n",
       " ('technique', 0.9434919357299805),\n",
       " ('performance', 0.9420003890991211),\n",
       " ('ensemble', 0.9411723613739014),\n",
       " ('called', 0.9368484616279602)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.wv.most_similar(['regression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "74c078b2-bb4e-42ff-bb32-ebb6e941113e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchword = 'regression'\n",
    "search_list = [sent for sent in sentence_list if searchword in sent]\n",
    "len(search_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe13c55-1635-4f7c-8a22-38f0d50a28f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
