{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b77ce26c",
   "metadata": {},
   "source": [
    "# Search Engine for Medium Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e9f357",
   "metadata": {},
   "source": [
    "- **Tokenization**\n",
    "- **Word Co Occurence Matrix**\n",
    "- **Continouous Bag of Words (CBoW)**\n",
    "- **Word2Vec**\n",
    "- **Search Articles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1120d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "\n",
    "import nltk, re, string, contractions\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d202a6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>author</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://towardsdatascience.com/ensemble-method...</td>\n",
       "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
       "      <td>Understanding the key concepts of ensemble lea...</td>\n",
       "      <td>Joseph Rocca</td>\n",
       "      <td>20</td>\n",
       "      <td>This post was co-written with Baptiste Rocca.\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://towardsdatascience.com/understanding-a...</td>\n",
       "      <td>Understanding AUC - ROC Curve</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>Sarang Narkhede</td>\n",
       "      <td>5</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://towardsdatascience.com/how-to-work-wit...</td>\n",
       "      <td>How to work with object detection datasets in ...</td>\n",
       "      <td>A comprehensive guide to defining, loading, ex...</td>\n",
       "      <td>Eric Hofesmann</td>\n",
       "      <td>10</td>\n",
       "      <td>Microsoft's Common Objects in Context dataset ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://towardsdatascience.com/11-dimensionali...</td>\n",
       "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
       "      <td>Reduce the size of your dataset while keeping ...</td>\n",
       "      <td>Rukshan Pramoditha</td>\n",
       "      <td>16</td>\n",
       "      <td>In both Statistics and Machine Learning, the n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://towardsdatascience.com/the-time-series...</td>\n",
       "      <td>The Time Series Transformer</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>Theodoros Ntakouris</td>\n",
       "      <td>6</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://towardsdatascience.com/ensemble-method...   \n",
       "1  https://towardsdatascience.com/understanding-a...   \n",
       "2  https://towardsdatascience.com/how-to-work-wit...   \n",
       "3  https://towardsdatascience.com/11-dimensionali...   \n",
       "4  https://towardsdatascience.com/the-time-series...   \n",
       "\n",
       "                                               title  \\\n",
       "0   Ensemble methods: bagging, boosting and stacking   \n",
       "1                      Understanding AUC - ROC Curve   \n",
       "2  How to work with object detection datasets in ...   \n",
       "3  11 Dimensionality reduction techniques you sho...   \n",
       "4                        The Time Series Transformer   \n",
       "\n",
       "                                           sub_title               author  \\\n",
       "0  Understanding the key concepts of ensemble lea...         Joseph Rocca   \n",
       "1  In Machine Learning, performance measurement i...      Sarang Narkhede   \n",
       "2  A comprehensive guide to defining, loading, ex...       Eric Hofesmann   \n",
       "3  Reduce the size of your dataset while keeping ...   Rukshan Pramoditha   \n",
       "4  Attention Is All You Need they said. Is it a m...  Theodoros Ntakouris   \n",
       "\n",
       "   reading_time                                               text  id  \n",
       "0            20  This post was co-written with Baptiste Rocca.\\...   1  \n",
       "1             5  In Machine Learning, performance measurement i...   2  \n",
       "2            10  Microsoft's Common Objects in Context dataset ...   3  \n",
       "3            16  In both Statistics and Machine Learning, the n...   4  \n",
       "4             6  Attention Is All You Need they said. Is it a m...   5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(r'F:\\Muthu_2023\\Personal\\NextStep\\NLP\\NLP\\Dataset\\medium_articles_v3.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c2785cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.drop(66)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7493e3e",
   "metadata": {},
   "source": [
    "`As per Analysis, Article 67 contains 10000+ unique words due to the presence of names of google scholars`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a01025d",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fabf266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(text):\n",
    "    sent_tokens = sent_tokenize(text)\n",
    "    stop_words = stopwords.words('English')\n",
    "    sent_processed = []\n",
    "    for sent in sent_tokens:\n",
    "        sent = re.sub(r'[^a-zA-Z0-9 ]',' ', contractions.fix(sent.lower()))\n",
    "        sent = re.sub(r'https://[^\\s\\n\\r]+', '', sent) #Remove links\n",
    "        sent = re.sub(r'http://[^\\s\\n\\r]+', '', sent)\n",
    "        sent = re.sub(r'[^a-zA-Z0-9 ]',' ', sent)\n",
    "        word_list = []\n",
    "        for word in sent.split():\n",
    "            if word not in stop_words and len(word.strip()) > 1 and not word.isnumeric() and not bool(re.search(r'\\d', word)) and len(word.strip()) < 20:\n",
    "                word_list.append(word)\n",
    "        if len(word_list)>0:\n",
    "            sent_processed.append(' '.join(word_list))\n",
    "    return(sent_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b109a559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>author</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://towardsdatascience.com/ensemble-method...</td>\n",
       "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
       "      <td>Understanding the key concepts of ensemble lea...</td>\n",
       "      <td>Joseph Rocca</td>\n",
       "      <td>20</td>\n",
       "      <td>This post was co-written with Baptiste Rocca.\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>[post co written baptiste rocca, unity strengt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://towardsdatascience.com/understanding-a...</td>\n",
       "      <td>Understanding AUC - ROC Curve</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>Sarang Narkhede</td>\n",
       "      <td>5</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>2</td>\n",
       "      <td>[machine learning performance measurement esse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://towardsdatascience.com/how-to-work-wit...</td>\n",
       "      <td>How to work with object detection datasets in ...</td>\n",
       "      <td>A comprehensive guide to defining, loading, ex...</td>\n",
       "      <td>Eric Hofesmann</td>\n",
       "      <td>10</td>\n",
       "      <td>Microsoft's Common Objects in Context dataset ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[microsoft common objects context dataset coco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://towardsdatascience.com/11-dimensionali...</td>\n",
       "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
       "      <td>Reduce the size of your dataset while keeping ...</td>\n",
       "      <td>Rukshan Pramoditha</td>\n",
       "      <td>16</td>\n",
       "      <td>In both Statistics and Machine Learning, the n...</td>\n",
       "      <td>4</td>\n",
       "      <td>[statistics machine learning number attributes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://towardsdatascience.com/the-time-series...</td>\n",
       "      <td>The Time Series Transformer</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>Theodoros Ntakouris</td>\n",
       "      <td>6</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>5</td>\n",
       "      <td>[attention need said, robust convolution, hack...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://towardsdatascience.com/ensemble-method...   \n",
       "1  https://towardsdatascience.com/understanding-a...   \n",
       "2  https://towardsdatascience.com/how-to-work-wit...   \n",
       "3  https://towardsdatascience.com/11-dimensionali...   \n",
       "4  https://towardsdatascience.com/the-time-series...   \n",
       "\n",
       "                                               title  \\\n",
       "0   Ensemble methods: bagging, boosting and stacking   \n",
       "1                      Understanding AUC - ROC Curve   \n",
       "2  How to work with object detection datasets in ...   \n",
       "3  11 Dimensionality reduction techniques you sho...   \n",
       "4                        The Time Series Transformer   \n",
       "\n",
       "                                           sub_title               author  \\\n",
       "0  Understanding the key concepts of ensemble lea...         Joseph Rocca   \n",
       "1  In Machine Learning, performance measurement i...      Sarang Narkhede   \n",
       "2  A comprehensive guide to defining, loading, ex...       Eric Hofesmann   \n",
       "3  Reduce the size of your dataset while keeping ...   Rukshan Pramoditha   \n",
       "4  Attention Is All You Need they said. Is it a m...  Theodoros Ntakouris   \n",
       "\n",
       "   reading_time                                               text  id  \\\n",
       "0            20  This post was co-written with Baptiste Rocca.\\...   1   \n",
       "1             5  In Machine Learning, performance measurement i...   2   \n",
       "2            10  Microsoft's Common Objects in Context dataset ...   3   \n",
       "3            16  In both Statistics and Machine Learning, the n...   4   \n",
       "4             6  Attention Is All You Need they said. Is it a m...   5   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  [post co written baptiste rocca, unity strengt...  \n",
       "1  [machine learning performance measurement esse...  \n",
       "2  [microsoft common objects context dataset coco...  \n",
       "3  [statistics machine learning number attributes...  \n",
       "4  [attention need said, robust convolution, hack...  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['transformed_text'] = raw_data['text'].apply(text_preprocess)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4d48795c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   link              208 non-null    object\n",
      " 1   title             208 non-null    object\n",
      " 2   sub_title         208 non-null    object\n",
      " 3   author            208 non-null    object\n",
      " 4   reading_time      208 non-null    int64 \n",
      " 5   text              208 non-null    object\n",
      " 6   id                208 non-null    int64 \n",
      " 7   transformed_text  208 non-null    object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 13.1+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a59db35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d2d3cb",
   "metadata": {},
   "source": [
    "## Word Co Occurence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c246eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list = raw_data['transformed_text'].explode()\n",
    "voc_list = sent_list.str.split().explode().unique()\n",
    "print('Vocabulary Size: ', len(voc_list), 'No. of sentences: ', len(sent_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e9fe0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for sentence in sent_list:\n",
    "    words = sentence.split()\n",
    "    for i in range(len(words)-2):\n",
    "        if (words[i], words[i+1]) not in d:\n",
    "            if (words[i+1], words[i]) not in d:\n",
    "                d[(words[i], words[i+1])] = 1\n",
    "            else:\n",
    "                d[(words[i+1], words[i])] += 1\n",
    "        else:\n",
    "            d[(words[i], words[i+1])] += 1\n",
    "            \n",
    "        if (words[i], words[i+2]) not in d:\n",
    "            if (words[i+2], words[i]) not in d:\n",
    "                d[(words[i], words[i+2])] = 1\n",
    "            else:\n",
    "                d[(words[i+2], words[i])] += 1\n",
    "        else:\n",
    "            d[(words[i], words[i+2])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1dd890bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('post', 'co'): 4,\n",
       " ('post', 'written'): 7,\n",
       " ('co', 'written'): 3,\n",
       " ('co', 'baptiste'): 3,\n",
       " ('written', 'baptiste'): 5,\n",
       " ('written', 'rocca'): 5,\n",
       " ('old', 'saying'): 1,\n",
       " ('old', 'expresses'): 1,\n",
       " ('saying', 'expresses'): 1,\n",
       " ('saying', 'pretty'): 1,\n",
       " ('expresses', 'pretty'): 1,\n",
       " ('expresses', 'well'): 1,\n",
       " ('pretty', 'well'): 5,\n",
       " ('pretty', 'underlying'): 1,\n",
       " ('well', 'underlying'): 1,\n",
       " ('well', 'idea'): 1,\n",
       " ('underlying', 'idea'): 1,\n",
       " ('underlying', 'rules'): 1,\n",
       " ('idea', 'rules'): 3,\n",
       " ('idea', 'powerful'): 2,\n",
       " ('rules', 'powerful'): 1,\n",
       " ('rules', 'ensemble'): 1,\n",
       " ('powerful', 'ensemble'): 1,\n",
       " ('powerful', 'methods'): 1,\n",
       " ('ensemble', 'methods'): 7,\n",
       " ('ensemble', 'machine'): 2,\n",
       " ('methods', 'machine'): 4,\n",
       " ('methods', 'learning'): 7,\n",
       " ('roughly', 'ensemble'): 1,\n",
       " ('roughly', 'learning'): 1,\n",
       " ('ensemble', 'learning'): 9,\n",
       " ('learning', 'often'): 3,\n",
       " ('methods', 'often'): 1,\n",
       " ('methods', 'trust'): 1,\n",
       " ('often', 'trust'): 1,\n",
       " ('often', 'top'): 2,\n",
       " ('trust', 'top'): 1,\n",
       " ('trust', 'rankings'): 1,\n",
       " ('top', 'rankings'): 2,\n",
       " ('top', 'many'): 2,\n",
       " ('rankings', 'many'): 1,\n",
       " ('rankings', 'machine'): 1,\n",
       " ('many', 'machine'): 3,\n",
       " ('many', 'learning'): 7,\n",
       " ('machine', 'learning'): 474,\n",
       " ('machine', 'competitions'): 2,\n",
       " ('learning', 'competitions'): 2,\n",
       " ('learning', 'including'): 1,\n",
       " ('competitions', 'including'): 2,\n",
       " ('competitions', 'kaggle'): 3,\n",
       " ('including', 'kaggle'): 1,\n",
       " ('kaggle', 'based'): 1,\n",
       " ('competitions', 'based'): 1,\n",
       " ('competitions', 'hypothesis'): 1,\n",
       " ('based', 'hypothesis'): 1,\n",
       " ('based', 'combining'): 1,\n",
       " ('hypothesis', 'combining'): 1,\n",
       " ('hypothesis', 'multiple'): 1,\n",
       " ('combining', 'multiple'): 3,\n",
       " ('combining', 'models'): 3,\n",
       " ('multiple', 'models'): 5,\n",
       " ('multiple', 'together'): 1,\n",
       " ('models', 'together'): 2,\n",
       " ('models', 'often'): 3,\n",
       " ('together', 'often'): 1,\n",
       " ('together', 'produce'): 2,\n",
       " ('often', 'produce'): 1,\n",
       " ('often', 'much'): 2,\n",
       " ('produce', 'much'): 2,\n",
       " ('produce', 'powerful'): 1,\n",
       " ('much', 'powerful'): 2,\n",
       " ('much', 'model'): 8,\n",
       " ('purpose', 'post'): 2,\n",
       " ('purpose', 'introduce'): 1,\n",
       " ('post', 'introduce'): 3,\n",
       " ('post', 'various'): 1,\n",
       " ('introduce', 'various'): 1,\n",
       " ('introduce', 'notions'): 1,\n",
       " ('various', 'notions'): 1,\n",
       " ('various', 'ensemble'): 1,\n",
       " ('notions', 'ensemble'): 2,\n",
       " ('notions', 'learning'): 2,\n",
       " ('give', 'reader'): 2,\n",
       " ('give', 'necessary'): 1,\n",
       " ('reader', 'necessary'): 1,\n",
       " ('reader', 'keys'): 1,\n",
       " ('necessary', 'keys'): 1,\n",
       " ('necessary', 'well'): 1,\n",
       " ('keys', 'well'): 2,\n",
       " ('keys', 'understand'): 1,\n",
       " ('well', 'understand'): 3,\n",
       " ('well', 'use'): 4,\n",
       " ('understand', 'use'): 1,\n",
       " ('understand', 'related'): 2,\n",
       " ('use', 'related'): 1,\n",
       " ('use', 'methods'): 8,\n",
       " ('related', 'methods'): 1,\n",
       " ('related', 'able'): 1,\n",
       " ('methods', 'able'): 1,\n",
       " ('methods', 'design'): 1,\n",
       " ('able', 'design'): 1,\n",
       " ('able', 'adapted'): 1,\n",
       " ('design', 'adapted'): 1,\n",
       " ('design', 'solutions'): 2,\n",
       " ('adapted', 'solutions'): 1,\n",
       " ('adapted', 'needed'): 1,\n",
       " ('discuss', 'well'): 1,\n",
       " ('discuss', 'known'): 1,\n",
       " ('well', 'known'): 20,\n",
       " ('well', 'notions'): 1,\n",
       " ('known', 'notions'): 1,\n",
       " ('known', 'boostrapping'): 1,\n",
       " ('notions', 'boostrapping'): 1,\n",
       " ('notions', 'bagging'): 3,\n",
       " ('boostrapping', 'bagging'): 1,\n",
       " ('boostrapping', 'random'): 1,\n",
       " ('bagging', 'random'): 4,\n",
       " ('bagging', 'forest'): 3,\n",
       " ('random', 'forest'): 62,\n",
       " ('random', 'boosting'): 2,\n",
       " ('forest', 'boosting'): 2,\n",
       " ('forest', 'stacking'): 1,\n",
       " ('boosting', 'stacking'): 3,\n",
       " ('boosting', 'many'): 1,\n",
       " ('stacking', 'many'): 1,\n",
       " ('stacking', 'others'): 1,\n",
       " ('many', 'others'): 5,\n",
       " ('many', 'basis'): 3,\n",
       " ('others', 'basis'): 1,\n",
       " ('others', 'ensemble'): 1,\n",
       " ('basis', 'ensemble'): 1,\n",
       " ('basis', 'learning'): 2,\n",
       " ('order', 'make'): 9,\n",
       " ('order', 'link'): 1,\n",
       " ('make', 'link'): 4,\n",
       " ('make', 'methods'): 1,\n",
       " ('link', 'methods'): 1,\n",
       " ('link', 'clear'): 2,\n",
       " ('methods', 'clear'): 1,\n",
       " ('methods', 'possible'): 2,\n",
       " ('clear', 'possible'): 2,\n",
       " ('clear', 'try'): 2,\n",
       " ('possible', 'try'): 4,\n",
       " ('possible', 'present'): 2,\n",
       " ('try', 'present'): 1,\n",
       " ('try', 'much'): 5,\n",
       " ('present', 'much'): 1,\n",
       " ('present', 'broader'): 1,\n",
       " ('much', 'broader'): 1,\n",
       " ('much', 'logical'): 1,\n",
       " ('broader', 'logical'): 1,\n",
       " ('broader', 'framework'): 1,\n",
       " ('logical', 'framework'): 1,\n",
       " ('logical', 'hope'): 1,\n",
       " ('framework', 'hope'): 1,\n",
       " ('framework', 'easier'): 1,\n",
       " ('hope', 'easier'): 1,\n",
       " ('hope', 'understand'): 2,\n",
       " ('easier', 'understand'): 5,\n",
       " ('easier', 'remember'): 1,\n",
       " ('first', 'section'): 4,\n",
       " ('first', 'post'): 5,\n",
       " ('section', 'post'): 2,\n",
       " ('section', 'present'): 3,\n",
       " ('post', 'present'): 1,\n",
       " ('post', 'notions'): 1,\n",
       " ('present', 'notions'): 1,\n",
       " ('present', 'weak'): 1,\n",
       " ('notions', 'weak'): 1,\n",
       " ('notions', 'strong'): 1,\n",
       " ('weak', 'strong'): 4,\n",
       " ('weak', 'learners'): 30,\n",
       " ('strong', 'learners'): 4,\n",
       " ('strong', 'introduce'): 1,\n",
       " ('learners', 'introduce'): 1,\n",
       " ('learners', 'three'): 2,\n",
       " ('introduce', 'three'): 1,\n",
       " ('introduce', 'main'): 1,\n",
       " ('three', 'main'): 3,\n",
       " ('three', 'ensemble'): 1,\n",
       " ('main', 'ensemble'): 1,\n",
       " ('main', 'learning'): 2,\n",
       " ('learning', 'bagging'): 1,\n",
       " ('methods', 'bagging'): 4,\n",
       " ('methods', 'boosting'): 4,\n",
       " ('bagging', 'boosting'): 9,\n",
       " ('bagging', 'stacking'): 2,\n",
       " ('second', 'section'): 2,\n",
       " ('second', 'focused'): 3,\n",
       " ('section', 'focused'): 2,\n",
       " ('section', 'bagging'): 1,\n",
       " ('focused', 'bagging'): 1,\n",
       " ('focused', 'discuss'): 1,\n",
       " ('bagging', 'discuss'): 1,\n",
       " ('discuss', 'notions'): 4,\n",
       " ('discuss', 'bootstrapping'): 1,\n",
       " ('notions', 'bootstrapping'): 2,\n",
       " ('bootstrapping', 'bagging'): 2,\n",
       " ('bootstrapping', 'random'): 2,\n",
       " ('bagging', 'forests'): 1,\n",
       " ('third', 'section'): 1,\n",
       " ('third', 'present'): 1,\n",
       " ('section', 'boosting'): 1,\n",
       " ('present', 'boosting'): 1,\n",
       " ('present', 'particular'): 1,\n",
       " ('boosting', 'particular'): 1,\n",
       " ('boosting', 'two'): 3,\n",
       " ('particular', 'two'): 2,\n",
       " ('particular', 'popular'): 1,\n",
       " ('two', 'popular'): 4,\n",
       " ('two', 'variants'): 1,\n",
       " ('popular', 'variants'): 1,\n",
       " ('popular', 'adaptative'): 1,\n",
       " ('variants', 'adaptative'): 1,\n",
       " ('variants', 'boosting'): 1,\n",
       " ('adaptative', 'boosting'): 4,\n",
       " ('adaptative', 'adaboost'): 1,\n",
       " ('boosting', 'adaboost'): 6,\n",
       " ('boosting', 'gradient'): 11,\n",
       " ('adaboost', 'gradient'): 3,\n",
       " ('finally', 'fourth'): 1,\n",
       " ('finally', 'section'): 4,\n",
       " ('fourth', 'section'): 1,\n",
       " ('fourth', 'give'): 1,\n",
       " ('section', 'give'): 3,\n",
       " ('section', 'overview'): 1,\n",
       " ('give', 'overview'): 7,\n",
       " ('give', 'stacking'): 1,\n",
       " ('learning', 'learning'): 14,\n",
       " ('machine', 'paradigm'): 1,\n",
       " ('learning', 'paradigm'): 1,\n",
       " ('learning', 'multiple'): 2,\n",
       " ('paradigm', 'multiple'): 1,\n",
       " ('paradigm', 'models'): 1,\n",
       " ('multiple', 'often'): 4,\n",
       " ('models', 'called'): 1,\n",
       " ('often', 'called'): 8,\n",
       " ('often', 'weak'): 1,\n",
       " ('called', 'weak'): 1,\n",
       " ('called', 'learners'): 2,\n",
       " ('weak', 'trained'): 3,\n",
       " ('learners', 'trained'): 3,\n",
       " ('learners', 'solve'): 1,\n",
       " ('trained', 'solve'): 2,\n",
       " ('trained', 'problem'): 1,\n",
       " ('solve', 'problem'): 27,\n",
       " ('solve', 'combined'): 1,\n",
       " ('problem', 'combined'): 1,\n",
       " ('problem', 'get'): 5,\n",
       " ('combined', 'get'): 1,\n",
       " ('combined', 'better'): 1,\n",
       " ('get', 'better'): 25,\n",
       " ('get', 'results'): 3,\n",
       " ('main', 'hypothesis'): 2,\n",
       " ('main', 'weak'): 1,\n",
       " ('hypothesis', 'weak'): 1,\n",
       " ('hypothesis', 'models'): 1,\n",
       " ('weak', 'models'): 4,\n",
       " ('weak', 'correctly'): 1,\n",
       " ('models', 'correctly'): 1,\n",
       " ('models', 'combined'): 2,\n",
       " ('correctly', 'combined'): 1,\n",
       " ('correctly', 'obtain'): 1,\n",
       " ('combined', 'obtain'): 1,\n",
       " ('combined', 'accurate'): 1,\n",
       " ('obtain', 'accurate'): 3,\n",
       " ('obtain', 'robust'): 1,\n",
       " ('accurate', 'robust'): 3,\n",
       " ('accurate', 'models'): 1,\n",
       " ('machine', 'matter'): 1,\n",
       " ('learning', 'matter'): 1,\n",
       " ('learning', 'facing'): 1,\n",
       " ('matter', 'facing'): 1,\n",
       " ('matter', 'classification'): 3,\n",
       " ('facing', 'classification'): 2,\n",
       " ('facing', 'regression'): 1,\n",
       " ('classification', 'regression'): 18,\n",
       " ('classification', 'problem'): 14,\n",
       " ('regression', 'problem'): 6,\n",
       " ('regression', 'choice'): 1,\n",
       " ('problem', 'choice'): 2,\n",
       " ('problem', 'model'): 5,\n",
       " ('choice', 'model'): 4,\n",
       " ('choice', 'extremely'): 1,\n",
       " ('model', 'extremely'): 2,\n",
       " ('model', 'important'): 4,\n",
       " ('extremely', 'important'): 4,\n",
       " ('extremely', 'chance'): 1,\n",
       " ('important', 'chance'): 1,\n",
       " ('important', 'obtain'): 1,\n",
       " ('chance', 'obtain'): 1,\n",
       " ('chance', 'good'): 3,\n",
       " ('obtain', 'good'): 1,\n",
       " ('obtain', 'results'): 1,\n",
       " ('choice', 'depend'): 1,\n",
       " ('choice', 'many'): 1,\n",
       " ('depend', 'many'): 1,\n",
       " ('depend', 'variables'): 1,\n",
       " ('many', 'variables'): 4,\n",
       " ('many', 'problem'): 4,\n",
       " ('variables', 'problem'): 1,\n",
       " ('variables', 'quantity'): 1,\n",
       " ('problem', 'quantity'): 1,\n",
       " ('problem', 'data'): 10,\n",
       " ('quantity', 'data'): 1,\n",
       " ('quantity', 'dimensionality'): 1,\n",
       " ('data', 'dimensionality'): 7,\n",
       " ('data', 'space'): 14,\n",
       " ('dimensionality', 'space'): 4,\n",
       " ('dimensionality', 'distribution'): 1,\n",
       " ('space', 'distribution'): 6,\n",
       " ('space', 'hypothesis'): 1,\n",
       " ('distribution', 'hypothesis'): 2,\n",
       " ('distribution', 'low'): 2,\n",
       " ('hypothesis', 'low'): 1,\n",
       " ('hypothesis', 'bias'): 1,\n",
       " ('low', 'bias'): 6,\n",
       " ('low', 'low'): 5,\n",
       " ('bias', 'variance'): 16,\n",
       " ('low', 'variance'): 7,\n",
       " ('low', 'although'): 1,\n",
       " ('variance', 'although'): 1,\n",
       " ('variance', 'often'): 2,\n",
       " ('although', 'often'): 1,\n",
       " ('although', 'vary'): 1,\n",
       " ('often', 'vary'): 1,\n",
       " ('often', 'opposite'): 1,\n",
       " ('vary', 'opposite'): 2,\n",
       " ('vary', 'directions'): 2,\n",
       " ('opposite', 'directions'): 1,\n",
       " ('opposite', 'two'): 1,\n",
       " ('directions', 'two'): 1,\n",
       " ('directions', 'fundamental'): 1,\n",
       " ('two', 'fundamental'): 1,\n",
       " ('two', 'features'): 12,\n",
       " ('fundamental', 'features'): 1,\n",
       " ('fundamental', 'expected'): 1,\n",
       " ('features', 'expected'): 1,\n",
       " ('features', 'model'): 11,\n",
       " ('indeed', 'able'): 1,\n",
       " ('indeed', 'solve'): 1,\n",
       " ('able', 'solve'): 4,\n",
       " ('able', 'problem'): 2,\n",
       " ('solve', 'want'): 2,\n",
       " ('problem', 'want'): 2,\n",
       " ('want', 'model'): 8,\n",
       " ('want', 'enough'): 2,\n",
       " ('model', 'enough'): 5,\n",
       " ('model', 'degrees'): 1,\n",
       " ('enough', 'degrees'): 2,\n",
       " ('enough', 'freedom'): 2,\n",
       " ('degrees', 'freedom'): 9,\n",
       " ('degrees', 'resolve'): 1,\n",
       " ('freedom', 'resolve'): 1,\n",
       " ('freedom', 'underlying'): 1,\n",
       " ('resolve', 'underlying'): 1,\n",
       " ('resolve', 'complexity'): 1,\n",
       " ('underlying', 'complexity'): 2,\n",
       " ('underlying', 'data'): 2,\n",
       " ('complexity', 'data'): 1,\n",
       " ('complexity', 'working'): 1,\n",
       " ('data', 'working'): 9,\n",
       " ('data', 'also'): 19,\n",
       " ('working', 'also'): 7,\n",
       " ('working', 'want'): 2,\n",
       " ('also', 'want'): 5,\n",
       " ('also', 'much'): 7,\n",
       " ('want', 'much'): 13,\n",
       " ('want', 'degrees'): 1,\n",
       " ('much', 'degrees'): 2,\n",
       " ('much', 'freedom'): 1,\n",
       " ('degrees', 'avoid'): 1,\n",
       " ('freedom', 'avoid'): 1,\n",
       " ('freedom', 'high'): 3,\n",
       " ('avoid', 'high'): 2,\n",
       " ('avoid', 'variance'): 1,\n",
       " ('high', 'variance'): 11,\n",
       " ('high', 'robust'): 2,\n",
       " ('well', 'bias'): 1,\n",
       " ('known', 'bias'): 1,\n",
       " ('known', 'variance'): 1,\n",
       " ('bias', 'tradeoff'): 1,\n",
       " ('ensemble', 'theory'): 1,\n",
       " ('learning', 'theory'): 2,\n",
       " ('learning', 'call'): 4,\n",
       " ('theory', 'call'): 1,\n",
       " ('theory', 'weak'): 2,\n",
       " ('call', 'weak'): 1,\n",
       " ('call', 'learners'): 1,\n",
       " ('weak', 'base'): 1,\n",
       " ('learners', 'base'): 1,\n",
       " ('learners', 'models'): 3,\n",
       " ('base', 'models'): 11,\n",
       " ('models', 'models'): 1,\n",
       " ('models', 'used'): 7,\n",
       " ('models', 'building'): 5,\n",
       " ('used', 'building'): 4,\n",
       " ('used', 'blocks'): 1,\n",
       " ('building', 'blocks'): 4,\n",
       " ('building', 'designing'): 2,\n",
       " ('blocks', 'designing'): 1,\n",
       " ('blocks', 'complex'): 1,\n",
       " ('designing', 'complex'): 1,\n",
       " ('designing', 'models'): 1,\n",
       " ('complex', 'models'): 4,\n",
       " ('complex', 'combining'): 1,\n",
       " ('models', 'several'): 3,\n",
       " ('time', 'basics'): 1,\n",
       " ('time', 'models'): 4,\n",
       " ('basics', 'models'): 1,\n",
       " ('basics', 'perform'): 1,\n",
       " ('models', 'perform'): 2,\n",
       " ('models', 'well'): 4,\n",
       " ('perform', 'well'): 6,\n",
       " ('perform', 'either'): 1,\n",
       " ('well', 'either'): 1,\n",
       " ('well', 'high'): 4,\n",
       " ('either', 'high'): 1,\n",
       " ('either', 'bias'): 1,\n",
       " ('high', 'bias'): 6,\n",
       " ('high', 'low'): 23,\n",
       " ('bias', 'degree'): 1,\n",
       " ('low', 'degree'): 1,\n",
       " ('low', 'freedom'): 1,\n",
       " ('degree', 'freedom'): 5,\n",
       " ('degree', 'models'): 2,\n",
       " ('freedom', 'models'): 2,\n",
       " ('freedom', 'example'): 2,\n",
       " ('models', 'example'): 1,\n",
       " ('models', 'much'): 1,\n",
       " ('example', 'much'): 2,\n",
       " ('example', 'variance'): 3,\n",
       " ('much', 'variance'): 4,\n",
       " ('much', 'robust'): 2,\n",
       " ('variance', 'robust'): 2,\n",
       " ('robust', 'degree'): 1,\n",
       " ('high', 'degree'): 2,\n",
       " ('idea', 'ensemble'): 1,\n",
       " ('idea', 'methods'): 1,\n",
       " ('ensemble', 'try'): 3,\n",
       " ('methods', 'try'): 2,\n",
       " ('methods', 'reducing'): 1,\n",
       " ('try', 'reducing'): 1,\n",
       " ('try', 'bias'): 1,\n",
       " ('reducing', 'bias'): 3,\n",
       " ('reducing', 'variance'): 3,\n",
       " ('bias', 'weak'): 2,\n",
       " ('variance', 'weak'): 1,\n",
       " ('variance', 'learners'): 1,\n",
       " ('weak', 'combining'): 2,\n",
       " ('learners', 'combining'): 2,\n",
       " ('learners', 'several'): 1,\n",
       " ('combining', 'several'): 2,\n",
       " ('combining', 'together'): 1,\n",
       " ('several', 'together'): 2,\n",
       " ('several', 'order'): 1,\n",
       " ('together', 'order'): 1,\n",
       " ('together', 'create'): 1,\n",
       " ('order', 'create'): 1,\n",
       " ('order', 'strong'): 1,\n",
       " ('create', 'strong'): 2,\n",
       " ('create', 'learner'): 1,\n",
       " ('strong', 'learner'): 3,\n",
       " ('strong', 'ensemble'): 1,\n",
       " ('learner', 'ensemble'): 1,\n",
       " ('learner', 'model'): 1,\n",
       " ('ensemble', 'model'): 16,\n",
       " ('ensemble', 'achieves'): 1,\n",
       " ('model', 'achieves'): 1,\n",
       " ('model', 'better'): 15,\n",
       " ('achieves', 'better'): 1,\n",
       " ('achieves', 'performances'): 1,\n",
       " ('order', 'set'): 3,\n",
       " ('order', 'ensemble'): 3,\n",
       " ('set', 'ensemble'): 1,\n",
       " ('set', 'learning'): 1,\n",
       " ('ensemble', 'method'): 4,\n",
       " ('learning', 'method'): 2,\n",
       " ('learning', 'first'): 3,\n",
       " ('method', 'first'): 2,\n",
       " ('method', 'need'): 2,\n",
       " ('first', 'need'): 20,\n",
       " ('first', 'select'): 3,\n",
       " ('need', 'select'): 4,\n",
       " ('need', 'base'): 1,\n",
       " ('select', 'base'): 1,\n",
       " ('select', 'models'): 3,\n",
       " ('base', 'aggregated'): 1,\n",
       " ('time', 'including'): 2,\n",
       " ('time', 'well'): 7,\n",
       " ('including', 'well'): 2,\n",
       " ('including', 'known'): 1,\n",
       " ('well', 'bagging'): 1,\n",
       " ('known', 'bagging'): 1,\n",
       " ('known', 'boosting'): 1,\n",
       " ('boosting', 'single'): 1,\n",
       " ('methods', 'single'): 1,\n",
       " ('methods', 'base'): 1,\n",
       " ('single', 'base'): 1,\n",
       " ('single', 'learning'): 4,\n",
       " ('base', 'learning'): 3,\n",
       " ('base', 'algorithm'): 1,\n",
       " ('learning', 'algorithm'): 26,\n",
       " ('learning', 'used'): 14,\n",
       " ('algorithm', 'used'): 12,\n",
       " ('algorithm', 'homogeneous'): 1,\n",
       " ('used', 'homogeneous'): 1,\n",
       " ('used', 'weak'): 2,\n",
       " ('homogeneous', 'weak'): 2,\n",
       " ('homogeneous', 'learners'): 2,\n",
       " ('learners', 'different'): 4,\n",
       " ('trained', 'different'): 2,\n",
       " ('trained', 'ways'): 1,\n",
       " ('ensemble', 'obtain'): 4,\n",
       " ('model', 'obtain'): 5,\n",
       " ('model', 'said'): 1,\n",
       " ('obtain', 'said'): 1,\n",
       " ('obtain', 'homogeneous'): 1,\n",
       " ('however', 'also'): 4,\n",
       " ('however', 'exist'): 1,\n",
       " ('also', 'exist'): 1,\n",
       " ('also', 'methods'): 2,\n",
       " ('exist', 'methods'): 1,\n",
       " ('exist', 'use'): 2,\n",
       " ('methods', 'different'): 12,\n",
       " ('use', 'different'): 11,\n",
       " ('use', 'type'): 3,\n",
       " ('different', 'type'): 1,\n",
       " ('different', 'base'): 1,\n",
       " ('type', 'base'): 1,\n",
       " ('type', 'learning'): 2,\n",
       " ('base', 'algorithms'): 1,\n",
       " ('learning', 'algorithms'): 42,\n",
       " ('learning', 'heterogeneous'): 1,\n",
       " ('algorithms', 'heterogeneous'): 1,\n",
       " ('algorithms', 'weak'): 1,\n",
       " ('heterogeneous', 'weak'): 2,\n",
       " ('heterogeneous', 'learners'): 3,\n",
       " ('weak', 'combined'): 2,\n",
       " ('learners', 'combined'): 1,\n",
       " ('combined', 'heterogeneous'): 1,\n",
       " ('combined', 'ensembles'): 1,\n",
       " ('heterogeneous', 'ensembles'): 1,\n",
       " ('heterogeneous', 'model'): 1,\n",
       " ('one', 'important'): 16,\n",
       " ('one', 'point'): 17,\n",
       " ('important', 'point'): 3,\n",
       " ('important', 'choice'): 1,\n",
       " ('point', 'choice'): 2,\n",
       " ('point', 'weak'): 1,\n",
       " ('choice', 'weak'): 1,\n",
       " ('choice', 'learners'): 1,\n",
       " ('weak', 'coherent'): 1,\n",
       " ('learners', 'coherent'): 1,\n",
       " ('learners', 'way'): 2,\n",
       " ('coherent', 'way'): 1,\n",
       " ('coherent', 'aggregate'): 1,\n",
       " ('way', 'aggregate'): 1,\n",
       " ('way', 'models'): 2,\n",
       " ('choose', 'base'): 3,\n",
       " ('choose', 'models'): 3,\n",
       " ('base', 'low'): 2,\n",
       " ('models', 'low'): 4,\n",
       " ('models', 'bias'): 3,\n",
       " ('high', 'aggregating'): 2,\n",
       " ('variance', 'aggregating'): 1,\n",
       " ('variance', 'method'): 1,\n",
       " ('aggregating', 'method'): 2,\n",
       " ('aggregating', 'tends'): 2,\n",
       " ('method', 'tends'): 2,\n",
       " ('method', 'reduce'): 2,\n",
       " ('tends', 'reduce'): 2,\n",
       " ('tends', 'variance'): 1,\n",
       " ('reduce', 'variance'): 3,\n",
       " ('reduce', 'whereas'): 1,\n",
       " ('variance', 'whereas'): 2,\n",
       " ('variance', 'choose'): 1,\n",
       " ('whereas', 'choose'): 1,\n",
       " ('whereas', 'base'): 1,\n",
       " ('models', 'variance'): 3,\n",
       " ('bias', 'aggregating'): 1,\n",
       " ('bias', 'method'): 1,\n",
       " ('tends', 'bias'): 1,\n",
       " ('brings', 'us'): 3,\n",
       " ('brings', 'question'): 1,\n",
       " ('us', 'question'): 3,\n",
       " ('us', 'combine'): 3,\n",
       " ('question', 'combine'): 1,\n",
       " ('question', 'models'): 1,\n",
       " ('mention', 'three'): 1,\n",
       " ('mention', 'major'): 1,\n",
       " ('three', 'major'): 2,\n",
       " ('three', 'kinds'): 2,\n",
       " ('major', 'kinds'): 1,\n",
       " ('major', 'meta'): 1,\n",
       " ('kinds', 'meta'): 1,\n",
       " ('kinds', 'algorithms'): 2,\n",
       " ('meta', 'algorithms'): 2,\n",
       " ('meta', 'aims'): 1,\n",
       " ('algorithms', 'aims'): 1,\n",
       " ('algorithms', 'combining'): 1,\n",
       " ('aims', 'combining'): 1,\n",
       " ('aims', 'weak'): 1,\n",
       " ('weak', 'roughly'): 1,\n",
       " ('learners', 'roughly'): 1,\n",
       " ('learners', 'say'): 1,\n",
       " ('roughly', 'say'): 1,\n",
       " ('roughly', 'bagging'): 1,\n",
       " ('say', 'bagging'): 1,\n",
       " ('say', 'mainly'): 1,\n",
       " ('bagging', 'mainly'): 4,\n",
       " ('bagging', 'focus'): 1,\n",
       " ('mainly', 'focus'): 1,\n",
       " ('mainly', 'getting'): 2,\n",
       " ('focus', 'getting'): 1,\n",
       " ('focus', 'ensemble'): 1,\n",
       " ('getting', 'ensemble'): 1,\n",
       " ('getting', 'model'): 1,\n",
       " ('ensemble', 'less'): 2,\n",
       " ('model', 'less'): 8,\n",
       " ('model', 'variance'): 10,\n",
       " ('less', 'variance'): 3,\n",
       " ('less', 'components'): 3,\n",
       " ('variance', 'components'): 4,\n",
       " ('components', 'whereas'): 1,\n",
       " ('components', 'boosting'): 1,\n",
       " ('whereas', 'boosting'): 4,\n",
       " ('whereas', 'stacking'): 1,\n",
       " ('boosting', 'mainly'): 2,\n",
       " ('stacking', 'mainly'): 2,\n",
       " ('stacking', 'try'): 1,\n",
       " ('mainly', 'try'): 1,\n",
       " ('mainly', 'produce'): 1,\n",
       " ('try', 'produce'): 1,\n",
       " ('try', 'strong'): 1,\n",
       " ('produce', 'strong'): 1,\n",
       " ('produce', 'models'): 2,\n",
       " ('strong', 'models'): 2,\n",
       " ('strong', 'less'): 1,\n",
       " ('models', 'less'): 2,\n",
       " ('models', 'biased'): 1,\n",
       " ('less', 'biased'): 2,\n",
       " ('biased', 'components'): 1,\n",
       " ('biased', 'even'): 2,\n",
       " ('components', 'even'): 1,\n",
       " ('even', 'variance'): 1,\n",
       " ('even', 'also'): 3,\n",
       " ('variance', 'also'): 2,\n",
       " ('variance', 'reduced'): 1,\n",
       " ('following', 'sections'): 1,\n",
       " ('following', 'present'): 1,\n",
       " ('sections', 'present'): 1,\n",
       " ('sections', 'details'): 1,\n",
       " ('present', 'details'): 1,\n",
       " ('present', 'bagging'): 1,\n",
       " ('details', 'bagging'): 1,\n",
       " ('details', 'boosting'): 1,\n",
       " ('bagging', 'bit'): 1,\n",
       " ('boosting', 'bit'): 1,\n",
       " ('boosting', 'widely'): 1,\n",
       " ('bit', 'widely'): 1,\n",
       " ('bit', 'used'): 1,\n",
       " ('widely', 'used'): 12,\n",
       " ('widely', 'stacking'): 1,\n",
       " ('used', 'stacking'): 2,\n",
       " ('used', 'allow'): 2,\n",
       " ('stacking', 'allow'): 1,\n",
       " ('stacking', 'us'): 1,\n",
       " ('allow', 'us'): 11,\n",
       " ('allow', 'discuss'): 1,\n",
       " ('us', 'discuss'): 3,\n",
       " ('us', 'key'): 2,\n",
       " ('discuss', 'key'): 1,\n",
       " ('key', 'notions'): 2,\n",
       " ('key', 'ensemble'): 1,\n",
       " ('ensemble', 'giving'): 1,\n",
       " ('learning', 'giving'): 2,\n",
       " ('learning', 'brief'): 1,\n",
       " ('giving', 'brief'): 1,\n",
       " ('giving', 'overview'): 1,\n",
       " ('brief', 'overview'): 2,\n",
       " ('brief', 'stacking'): 1,\n",
       " ('parallel', 'methods'): 1,\n",
       " ('parallel', 'fit'): 1,\n",
       " ('methods', 'fit'): 1,\n",
       " ('fit', 'different'): 2,\n",
       " ('fit', 'considered'): 1,\n",
       " ('different', 'considered'): 1,\n",
       " ('considered', 'learners'): 1,\n",
       " ('considered', 'independently'): 1,\n",
       " ('learners', 'independently'): 1,\n",
       " ('learners', 'others'): 1,\n",
       " ('independently', 'others'): 2,\n",
       " ('independently', 'possible'): 1,\n",
       " ('others', 'possible'): 1,\n",
       " ('others', 'train'): 1,\n",
       " ('possible', 'train'): 1,\n",
       " ('possible', 'concurrently'): 1,\n",
       " ('famous', 'approach'): 1,\n",
       " ('famous', 'bagging'): 1,\n",
       " ('approach', 'bagging'): 2,\n",
       " ('approach', 'standing'): 1,\n",
       " ('bagging', 'standing'): 1,\n",
       " ('bagging', 'bootstrap'): 3,\n",
       " ('standing', 'bootstrap'): 1,\n",
       " ('standing', 'aggregating'): 1,\n",
       " ('bootstrap', 'aggregating'): 1,\n",
       " ('bootstrap', 'aims'): 1,\n",
       " ('aggregating', 'aims'): 1,\n",
       " ('aggregating', 'producing'): 1,\n",
       " ('aims', 'producing'): 1,\n",
       " ('aims', 'ensemble'): 1,\n",
       " ('producing', 'ensemble'): 1,\n",
       " ('producing', 'model'): 1,\n",
       " ('ensemble', 'robust'): 1,\n",
       " ('model', 'robust'): 3,\n",
       " ('model', 'individual'): 2,\n",
       " ('robust', 'individual'): 1,\n",
       " ('robust', 'models'): 2,\n",
       " ('individual', 'models'): 3,\n",
       " ('individual', 'composing'): 1,\n",
       " ('let', 'us'): 434,\n",
       " ('let', 'begin'): 4,\n",
       " ('us', 'begin'): 4,\n",
       " ('us', 'defining'): 2,\n",
       " ('begin', 'defining'): 2,\n",
       " ('begin', 'bootstrapping'): 1,\n",
       " ('statistical', 'technique'): 2,\n",
       " ('statistical', 'consists'): 1,\n",
       " ('technique', 'consists'): 2,\n",
       " ('technique', 'generating'): 1,\n",
       " ('consists', 'generating'): 2,\n",
       " ('consists', 'samples'): 1,\n",
       " ('generating', 'samples'): 1,\n",
       " ('generating', 'size'): 1,\n",
       " ('samples', 'size'): 3,\n",
       " ('samples', 'called'): 2,\n",
       " ('size', 'called'): 2,\n",
       " ('size', 'bootstrap'): 2,\n",
       " ('called', 'bootstrap'): 1,\n",
       " ('bootstrap', 'samples'): 13,\n",
       " ('bootstrap', 'initial'): 1,\n",
       " ('samples', 'initial'): 1,\n",
       " ('samples', 'dataset'): 3,\n",
       " ('initial', 'dataset'): 3,\n",
       " ('initial', 'size'): 2,\n",
       " ('dataset', 'size'): 3,\n",
       " ('dataset', 'randomly'): 3,\n",
       " ('size', 'randomly'): 1,\n",
       " ('size', 'drawing'): 1,\n",
       " ('randomly', 'drawing'): 2,\n",
       " ('randomly', 'replacement'): 1,\n",
       " ('drawing', 'replacement'): 1,\n",
       " ('drawing', 'observations'): 1,\n",
       " ('assumptions', 'samples'): 1,\n",
       " ('assumptions', 'pretty'): 1,\n",
       " ('samples', 'pretty'): 1,\n",
       " ('samples', 'good'): 1,\n",
       " ('pretty', 'good'): 14,\n",
       " ('pretty', 'statistical'): 1,\n",
       " ('good', 'statistical'): 1,\n",
       " ('good', 'properties'): 4,\n",
       " ('statistical', 'properties'): 2,\n",
       " ('statistical', 'first'): 1,\n",
       " ('properties', 'first'): 1,\n",
       " ('properties', 'approximation'): 1,\n",
       " ('first', 'approximation'): 1,\n",
       " ('first', 'seen'): 1,\n",
       " ('approximation', 'seen'): 1,\n",
       " ('approximation', 'drawn'): 1,\n",
       " ('seen', 'drawn'): 1,\n",
       " ('seen', 'directly'): 1,\n",
       " ('drawn', 'directly'): 1,\n",
       " ('drawn', 'true'): 2,\n",
       " ('directly', 'true'): 2,\n",
       " ('directly', 'underlying'): 1,\n",
       " ('true', 'underlying'): 2,\n",
       " ('true', 'often'): 1,\n",
       " ('underlying', 'often'): 1,\n",
       " ('underlying', 'unknown'): 2,\n",
       " ('often', 'unknown'): 1,\n",
       " ('often', 'data'): 8,\n",
       " ('unknown', 'data'): 2,\n",
       " ('unknown', 'distribution'): 2,\n",
       " ('data', 'distribution'): 18,\n",
       " ('data', 'independently'): 1,\n",
       " ('distribution', 'independently'): 1,\n",
       " ('distribution', 'others'): 1,\n",
       " ('considered', 'representative'): 2,\n",
       " ('considered', 'independent'): 1,\n",
       " ('representative', 'independent'): 2,\n",
       " ('representative', 'samples'): 1,\n",
       " ('independent', 'samples'): 7,\n",
       " ('independent', 'true'): 1,\n",
       " ('samples', 'true'): 3,\n",
       " ('samples', 'data'): 10,\n",
       " ('true', 'data'): 10,\n",
       " ('true', 'distribution'): 8,\n",
       " ('data', 'almost'): 2,\n",
       " ('hypothesis', 'verified'): 1,\n",
       " ('hypothesis', 'make'): 1,\n",
       " ('verified', 'make'): 1,\n",
       " ('verified', 'approximation'): 1,\n",
       " ('make', 'approximation'): 1,\n",
       " ('make', 'valid'): 1,\n",
       " ('approximation', 'valid'): 1,\n",
       " ('approximation', 'twofold'): 1,\n",
       " ('first', 'size'): 2,\n",
       " ('first', 'initial'): 1,\n",
       " ('initial', 'large'): 1,\n",
       " ('dataset', 'large'): 4,\n",
       " ('dataset', 'enough'): 2,\n",
       " ('large', 'enough'): 3,\n",
       " ('large', 'capture'): 1,\n",
       " ('enough', 'capture'): 1,\n",
       " ('enough', 'complexity'): 1,\n",
       " ('capture', 'complexity'): 1,\n",
       " ('capture', 'underlying'): 1,\n",
       " ('complexity', 'distribution'): 1,\n",
       " ('underlying', 'distribution'): 5,\n",
       " ('underlying', 'sampling'): 1,\n",
       " ('distribution', 'sampling'): 7,\n",
       " ('distribution', 'dataset'): 1,\n",
       " ('sampling', 'dataset'): 2,\n",
       " ('sampling', 'good'): 3,\n",
       " ('dataset', 'good'): 1,\n",
       " ('dataset', 'approximation'): 1,\n",
       " ('good', 'approximation'): 1,\n",
       " ('approximation', 'sampling'): 1,\n",
       " ('approximation', 'real'): 1,\n",
       " ('sampling', 'real'): 1,\n",
       " ('real', 'distribution'): 2,\n",
       " ('real', 'representativity'): 1,\n",
       " ('second', 'size'): 1,\n",
       " ('second', 'dataset'): 2,\n",
       " ('size', 'large'): 5,\n",
       " ('large', 'compared'): 1,\n",
       " ('enough', 'compared'): 1,\n",
       " ('enough', 'size'): 2,\n",
       " ('compared', 'size'): 3,\n",
       " ('compared', 'bootstrap'): 1,\n",
       " ('samples', 'samples'): 1,\n",
       " ('samples', 'much'): 2,\n",
       " ('samples', 'correlated'): 1,\n",
       " ('much', 'correlated'): 1,\n",
       " ('much', 'independence'): 1,\n",
       " ('notice', 'following'): 2,\n",
       " ('notice', 'sometimes'): 1,\n",
       " ('following', 'sometimes'): 1,\n",
       " ('following', 'make'): 5,\n",
       " ('sometimes', 'make'): 3,\n",
       " ('sometimes', 'reference'): 1,\n",
       " ('make', 'reference'): 1,\n",
       " ('make', 'properties'): 2,\n",
       " ('reference', 'properties'): 1,\n",
       " ('reference', 'representativity'): 1,\n",
       " ('properties', 'representativity'): 1,\n",
       " ('properties', 'independence'): 1,\n",
       " ('representativity', 'independence'): 2,\n",
       " ('representativity', 'bootstrap'): 2,\n",
       " ('independence', 'bootstrap'): 1,\n",
       " ('independence', 'samples'): 2,\n",
       " ('bootstrap', 'reader'): 1,\n",
       " ('samples', 'reader'): 1,\n",
       " ('samples', 'always'): 1,\n",
       " ('reader', 'always'): 1,\n",
       " ('reader', 'keep'): 1,\n",
       " ('always', 'keep'): 2,\n",
       " ('always', 'mind'): 2,\n",
       " ('keep', 'mind'): 22,\n",
       " ('keep', 'approximation'): 1,\n",
       " ('bootstrap', 'often'): 1,\n",
       " ('samples', 'often'): 1,\n",
       " ('samples', 'used'): 2,\n",
       " ('often', 'used'): 18,\n",
       " ('often', 'example'): 4,\n",
       " ('used', 'example'): 8,\n",
       " ('used', 'evaluate'): 1,\n",
       " ('example', 'evaluate'): 1,\n",
       " ('evaluate', 'variance'): 1,\n",
       " ('evaluate', 'confidence'): 1,\n",
       " ('variance', 'confidence'): 1,\n",
       " ('variance', 'intervals'): 1,\n",
       " ('confidence', 'intervals'): 7,\n",
       " ('confidence', 'statistical'): 1,\n",
       " ('intervals', 'statistical'): 1,\n",
       " ('intervals', 'estimators'): 1,\n",
       " ('definition', 'statistical'): 1,\n",
       " ('definition', 'estimator'): 1,\n",
       " ('statistical', 'estimator'): 1,\n",
       " ('statistical', 'function'): 1,\n",
       " ('estimator', 'function'): 1,\n",
       " ('estimator', 'observations'): 1,\n",
       " ('function', 'observations'): 2,\n",
       " ('function', 'random'): 8,\n",
       " ('observations', 'random'): 1,\n",
       " ('observations', 'variable'): 1,\n",
       " ('random', 'variable'): 37,\n",
       " ('random', 'variance'): 1,\n",
       " ('variable', 'variance'): 5,\n",
       " ('variable', 'coming'): 1,\n",
       " ('variance', 'coming'): 1,\n",
       " ('variance', 'observations'): 1,\n",
       " ('order', 'estimate'): 1,\n",
       " ('order', 'variance'): 1,\n",
       " ('estimate', 'variance'): 3,\n",
       " ('estimate', 'estimator'): 1,\n",
       " ('variance', 'estimator'): 3,\n",
       " ('variance', 'need'): 1,\n",
       " ('estimator', 'need'): 1,\n",
       " ('estimator', 'evaluate'): 1,\n",
       " ('need', 'evaluate'): 3,\n",
       " ('need', 'several'): 2,\n",
       " ('evaluate', 'several'): 1,\n",
       " ('evaluate', 'independent'): 1,\n",
       " ('several', 'independent'): 4,\n",
       " ('several', 'samples'): 2,\n",
       " ('independent', 'drawn'): 2,\n",
       " ('samples', 'drawn'): 1,\n",
       " ('samples', 'distribution'): 4,\n",
       " ('drawn', 'distribution'): 3,\n",
       " ('drawn', 'interest'): 2,\n",
       " ('cases', 'considering'): 1,\n",
       " ('cases', 'truly'): 1,\n",
       " ('considering', 'truly'): 1,\n",
       " ('considering', 'independent'): 1,\n",
       " ('truly', 'independent'): 1,\n",
       " ('truly', 'samples'): 1,\n",
       " ('independent', 'would'): 2,\n",
       " ('samples', 'would'): 1,\n",
       " ('samples', 'require'): 1,\n",
       " ('would', 'require'): 4,\n",
       " ('would', 'much'): 21,\n",
       " ('require', 'much'): 4,\n",
       " ('require', 'data'): 3,\n",
       " ('much', 'data'): 9,\n",
       " ('much', 'compared'): 3,\n",
       " ('data', 'compared'): 3,\n",
       " ('data', 'amount'): 9,\n",
       " ('compared', 'amount'): 1,\n",
       " ('compared', 'really'): 3,\n",
       " ('amount', 'really'): 1,\n",
       " ('amount', 'available'): 2,\n",
       " ('use', 'bootstrapping'): 1,\n",
       " ('use', 'generate'): 3,\n",
       " ('bootstrapping', 'generate'): 1,\n",
       " ('bootstrapping', 'several'): 1,\n",
       " ('generate', 'several'): 1,\n",
       " ('generate', 'bootstrap'): 2,\n",
       " ('several', 'bootstrap'): 1,\n",
       " ('bootstrap', 'considered'): 1,\n",
       " ('samples', 'considered'): 1,\n",
       " ('samples', 'almost'): 1,\n",
       " ('considered', 'almost'): 2,\n",
       " ('almost', 'representative'): 2,\n",
       " ('almost', 'almost'): 2,\n",
       " ('almost', 'independent'): 3,\n",
       " ('bootstrap', 'allow'): 1,\n",
       " ('samples', 'allow'): 1,\n",
       " ('samples', 'us'): 1,\n",
       " ('allow', 'approximate'): 1,\n",
       " ('us', 'approximate'): 1,\n",
       " ('us', 'variance'): 2,\n",
       " ('approximate', 'variance'): 2,\n",
       " ('approximate', 'estimator'): 1,\n",
       " ('variance', 'evaluating'): 1,\n",
       " ('estimator', 'evaluating'): 1,\n",
       " ('estimator', 'value'): 2,\n",
       " ('training', 'model'): 37,\n",
       " ('training', 'matter'): 1,\n",
       " ('model', 'matter'): 1,\n",
       " ('model', 'dealing'): 2,\n",
       " ('matter', 'dealing'): 1,\n",
       " ('dealing', 'classification'): 1,\n",
       " ('dealing', 'regression'): 2,\n",
       " ('regression', 'obtain'): 1,\n",
       " ('problem', 'obtain'): 1,\n",
       " ('problem', 'function'): 2,\n",
       " ('obtain', 'function'): 2,\n",
       " ('obtain', 'takes'): 1,\n",
       " ('function', 'takes'): 4,\n",
       " ('function', 'input'): 7,\n",
       " ('takes', 'input'): 10,\n",
       " ('takes', 'returns'): 1,\n",
       " ('input', 'returns'): 1,\n",
       " ('input', 'output'): 18,\n",
       " ('returns', 'output'): 3,\n",
       " ('returns', 'defined'): 1,\n",
       " ('output', 'defined'): 1,\n",
       " ('output', 'respect'): 1,\n",
       " ('defined', 'respect'): 1,\n",
       " ('defined', 'training'): 1,\n",
       " ('respect', 'training'): 1,\n",
       " ('respect', 'dataset'): 1,\n",
       " ('due', 'theoretical'): 1,\n",
       " ('due', 'variance'): 6,\n",
       " ('theoretical', 'variance'): 1,\n",
       " ('theoretical', 'training'): 1,\n",
       " ('variance', 'training'): 1,\n",
       " ('variance', 'dataset'): 1,\n",
       " ...}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27c031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a23d1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "for sentence in sent_list:\n",
    "    words = sentence.split()\n",
    "    for ind in range(len(words)):\n",
    "        pair_list = []\n",
    "        for sub_ind in range(ind - 2, ind + 3):\n",
    "            if sub_ind != ind and sub_ind >= 0 and sub_ind < len(words):\n",
    "                pair_list.append(words[sub_ind])                \n",
    "        if len(pair_list) > 0:\n",
    "            x_list.append(pair_list)\n",
    "            y_list.append([words[ind]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "89f136d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244928, 244928)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_list), len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c6ee99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes = voc_list, sparse_output=True) # Generates Multi label Encoding with sparse output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "08ac53a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<244928x19511 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 818906 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.fit_transform(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "77efbc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<244928x19511 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 244928 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.fit_transform(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "95ba9f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['post', 'co', 'written', ..., 'serotonin', 'gobbled', 'critic'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828c17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
