{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa681b26",
   "metadata": {},
   "source": [
    "# Email Auto Fill\n",
    "- **Text Preprocessing**\n",
    "    - *Contractions, Sentence Tokenization*\n",
    "- **Basic EDA**\n",
    "    - *Word Cloud*\n",
    "- **Probabilistic Language Models**\n",
    "    - *Unigram, Bigrams, Trigrams, N-grams*\n",
    "- **Model Evaluation**\n",
    "    - *Perplexity* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f309901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk, re, string, contractions\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import email\n",
    "from nltk.util import bigrams, trigrams\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be96ed0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      file  \\\n",
       "0           0     allen-p/_sent_mail/1.   \n",
       "1           1    allen-p/_sent_mail/10.   \n",
       "2           2   allen-p/_sent_mail/100.   \n",
       "3           3  allen-p/_sent_mail/1000.   \n",
       "4           4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...  \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...  \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...  \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...  \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'F:\\Muthu_2023\\Personal\\NextStep\\NLP\\NLP\\Dataset\\Email\\email_truncated.csv')\n",
    "# df = pd.read_csv(r'E:\\Nextstep\\NLP\\Dataset\\Email\\email_truncated.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed8925a",
   "metadata": {},
   "source": [
    "**Text Preprocessing:**\n",
    "- **`Using email library, extract body from the complete message`**\n",
    "- **`Remove all new line characters`**\n",
    "- **`Remove all non alpha numeric characters`**\n",
    "- **`Strip the and lower case the text`**\n",
    "- **`Apply contractions`**\n",
    "- **`Create a column with sentences as list elements for each message in main dataframe`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0e0476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMessage(message):\n",
    "    e = email.message_from_string(message)\n",
    "    return e.get_payload().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "33326d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenization(text):\n",
    "    sentence_list = sent_tokenize(text)\n",
    "    transformed_sent = []\n",
    "    for sentence in sentence_list:\n",
    "        sentence = (re.sub(\"[^a-zA-Z0-9 ]\", \"\", sentence))\n",
    "        words = []\n",
    "        for word in sentence.split():\n",
    "            if len(word) < 20 and word.strip().isalpha():\n",
    "                words.append(word.strip())\n",
    "        if len(words) > 0:\n",
    "            transformed_sent.append(\" \".join(words))\n",
    "    return transformed_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2f35122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(local_df):\n",
    "    local_df['content'] = local_df['message'].apply(extractMessage)\n",
    "    local_df['content'] = local_df['content'].str.replace(\"\\n\", \" \")\n",
    "    local_df['content'] = local_df['content'].apply(lambda x: re.sub(\"[^a-zA-Z0-9 \\.]\", \"\", x))\n",
    "    local_df['content'] = local_df['content'].str.strip().str.lower()\n",
    "    local_df['content'] = local_df['content'].apply(lambda x: contractions.fix(x))\n",
    "    local_df['sent_list'] = local_df['content'].apply(sentence_tokenization)\n",
    "    return local_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = text_preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3c82e",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25015aea",
   "metadata": {},
   "source": [
    "**`Histogram plot for number of words in a message`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d73e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['content'].apply(lambda x: len(x)), bins=1000)\n",
    "plt.xlim(0,10000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fc51db",
   "metadata": {},
   "source": [
    "**`Generate Word Count Vector for the complete corpus`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc3d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for sent_tokens in df['sent_list']:\n",
    "    for sent in sent_tokens:\n",
    "        for word in sent.split():\n",
    "            word = word.replace(\".\", \"\").strip()\n",
    "            if word in d:\n",
    "                d[word] += 1\n",
    "            else:\n",
    "                d[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205409fd",
   "metadata": {},
   "source": [
    "**`Sort Top N words by total count in the corpus `**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8a07391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 194347),\n",
       " ('to', 140013),\n",
       " ('and', 87514),\n",
       " ('a', 79911),\n",
       " ('of', 72795),\n",
       " ('in', 61234),\n",
       " ('you', 54237),\n",
       " ('for', 52873),\n",
       " ('is', 50794),\n",
       " ('on', 47504),\n",
       " ('i', 39791),\n",
       " ('this', 34549),\n",
       " ('that', 34048),\n",
       " ('not', 29304),\n",
       " ('be', 29176),\n",
       " ('will', 28690),\n",
       " ('from', 28524),\n",
       " ('with', 27117),\n",
       " ('at', 26695),\n",
       " ('have', 26266)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(d.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a01b28",
   "metadata": {},
   "source": [
    "***All Top20 words are Stopwords***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cf920",
   "metadata": {},
   "source": [
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243bfa67",
   "metadata": {},
   "source": [
    "**`Build Word cloud from the email body texts`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac8e0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "555eef11",
   "metadata": {},
   "source": [
    "# Bigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ecffbe",
   "metadata": {},
   "source": [
    "**`Generate bigram dictionary with frequency of occurence in {(currentword, nextword): freq}`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7395ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_dict = {}\n",
    "for message in df['sent_list']:\n",
    "    for sentence in message:\n",
    "        for words in bigrams(sentence.split()):\n",
    "            if words in bi_dict:\n",
    "                bi_dict[words] += 1\n",
    "            else:\n",
    "                bi_dict[words] = 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "eaa99d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_dict_prob = {}\n",
    "for w1, w2 in bi_dict:\n",
    "    bi_dict_prob[(w1, w2)] = bi_dict[(w1, w2)] / d[w1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff778d3",
   "metadata": {},
   "source": [
    "**`Sort the dictinary based on key and values`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b8e8cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_dict_sorted = dict(sorted(bi_dict_prob.items(), key=lambda x: (x[0][0], x[1]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b4df2555-5aa1-409c-98f9-427f0e8b7cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626705"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bi_dict_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ec7cf",
   "metadata": {},
   "source": [
    "**`Create data frame from the dictinary for easier processing`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d36610b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zypfje</td>\n",
       "      <td>baughmandon</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zy</td>\n",
       "      <td>for</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zwiebel</td>\n",
       "      <td>calls</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zwiebel</td>\n",
       "      <td>and</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zwerneman</td>\n",
       "      <td>jazztotalzonecom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0           level_1  Count\n",
       "0     zypfje       baughmandon    1.0\n",
       "1         zy               for    1.0\n",
       "2    zwiebel             calls    0.5\n",
       "3    zwiebel               and    0.5\n",
       "4  zwerneman  jazztotalzonecom    1.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_df = pd.DataFrame(data = bi_dict_sorted.values(), columns=['Count'], index=bi_dict_sorted.keys())\n",
    "bi_df.reset_index(inplace=True)\n",
    "bi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adacee34",
   "metadata": {},
   "source": [
    "**`Extract top N Next words in list for each Current word`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "94f177ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "filtered_bi = bi_df.drop('Count', axis=1).groupby('level_0').head(N)\n",
    "filtered_bi = filtered_bi.groupby('level_0')['level_1'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e2e7c3",
   "metadata": {},
   "source": [
    "**`Transform dataframe to dictionary with key as current word and values as N next words`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d47e6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bi_dict = dict()\n",
    "for i in range(len(filtered_bi)):\n",
    "    filtered_bi_dict[filtered_bi['level_0'].iloc[i]] = filtered_bi['level_1'].iloc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196f0dc",
   "metadata": {},
   "source": [
    "**`Derive the next N words for the current word from the dictionary`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "79f5ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nextwords(Queryword, in_dict):\n",
    "    if Queryword.lower() in in_dict:\n",
    "        return in_dict[Queryword.lower()]\n",
    "    else:\n",
    "        return \"Word not exist in dictionary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "597624a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am', 'have', 'will']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('I', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c6f62286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to', 'about', 'much']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('how', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5793e7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'be', 'get']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('to', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7e48c79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['following', 'last', 'new']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('the', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4c7878af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'have', 'rank']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('they', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3e47098d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'be', 'do']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('can', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edcd70a",
   "metadata": {},
   "source": [
    "**`Generate the next M sequence words for the current word`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e58f71f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron north america corp from the following the following the following\n"
     ]
    }
   ],
   "source": [
    "M = 10\n",
    "CurrWord = 'Enron'\n",
    "word_list = [CurrWord]\n",
    "for x in range(M):    \n",
    "    CurrWord = get_nextwords(CurrWord, filtered_bi_dict)[0]\n",
    "    word_list.append(CurrWord)\n",
    "print(\" \".join(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57819e63",
   "metadata": {},
   "source": [
    "# Trigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436813ea",
   "metadata": {},
   "source": [
    "**`Generate conditional probability of trigram`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d5e2bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_dict = {}\n",
    "tri_dict_prob = {}\n",
    "for message in df['sent_list']:\n",
    "    for sentence in message:\n",
    "        for words in trigrams(sentence.split()):\n",
    "            if words in tri_dict:\n",
    "                tri_dict[words] += 1\n",
    "            else:\n",
    "                tri_dict[words] = 1\n",
    "\n",
    "for words in tri_dict:\n",
    "    currwords = words[:-1]\n",
    "    tri_dict_prob[words] = tri_dict[words] / bi_dict[currwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556e535",
   "metadata": {},
   "source": [
    "**`Group Sort the dictionary based on the maximum likelyhood probability and create dataframe`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b165c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_dict_sort = dict(sorted(tri_dict_prob.items(), key = (lambda x: (x[0][:2], x[1])), reverse=True))\n",
    "tri_dict_df = pd.DataFrame(data = tri_dict_sort.values(), columns=['Count'], index=tri_dict_sort.keys())\n",
    "tri_dict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73601e2a",
   "metadata": {},
   "source": [
    "**`Extract Top N next words for each bigrams`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "99c4d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_dict_df_filtered = tri_dict_df.drop('Count', axis=1).reset_index().groupby(['level_0', 'level_1']).head(3)\n",
    "tri_dict_df_filtered = tri_dict_df_filtered.groupby(['level_0', 'level_1'])['level_2'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a8076",
   "metadata": {},
   "source": [
    "**`Convert DF to dictionary with currwords as index and next N words list as value`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0c7de553",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tri_dict = dict()\n",
    "for i in range(len(tri_dict_df_filtered)):\n",
    "    currwords = (tri_dict_df_filtered['level_0'].iloc[i], tri_dict_df_filtered['level_1'].iloc[i])\n",
    "    filtered_tri_dict[currwords] = tri_dict_df_filtered['level_2'].iloc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e87bc",
   "metadata": {},
   "source": [
    "**`Get next words list for the given bigram`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5956e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nextwords_tri(Query, in_dict):\n",
    "    words = tuple(Query.lower().split())\n",
    "    if words in in_dict:\n",
    "        return in_dict[words]\n",
    "    else:\n",
    "        return \"Words not exist in dictionary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d008c",
   "metadata": {},
   "source": [
    "**`Example results for random bigram`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8fc42762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not', 'going', 'sure']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords_tri('i am', filtered_tri_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2235fb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['been', 'not', 'a']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords_tri('i have', filtered_tri_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "36073e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'the', 'an']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords_tri('season with', filtered_tri_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5bcf87",
   "metadata": {},
   "source": [
    "**`Text Generation from the trigram model`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "46c3497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words_tri(seed, word_dict, seq):\n",
    "    word_query = seed.lower().split()\n",
    "    for x in range(seq):\n",
    "        nxtword = get_nextwords_tri(\" \".join(word_query[x:]), word_dict)\n",
    "        word_query.append(nxtword[0])\n",
    "    return \" \".join(word_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "71a39414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am not sure what you think of the season with a sore knee and is expected to play with his sore shoulder and neck W W'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_words_tri('I am', filtered_tri_dict, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fba5cca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how are you going to be a good idea to keep the tradition and organize a thanksgiving dinner i can do it all to brunch swcc am'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_words_tri('how are', filtered_tri_dict, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ecdd77e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i heard that you are not the intended recipient or authorized to receive for the year they rank in fantasy points allowed'"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_words_tri('I heard', filtered_tri_dict, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "dd623a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can we meet at the end of the season with a sore knee and is expected to play with his sore shoulder'"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_words_tri('can we', filtered_tri_dict, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d54e35",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255044bf",
   "metadata": {},
   "source": [
    "**`Model Perplexity score calcuation`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f692c",
   "metadata": {},
   "source": [
    "**`Read and transform test data`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1292b67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>baughman-d/power/cinergy_index/45.</td>\n",
       "      <td>Message-ID: &lt;11686348.1075848338607.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>baughman-d/power/cinergy_index/46.</td>\n",
       "      <td>Message-ID: &lt;18375400.1075848338630.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>baughman-d/power/cinergy_index/47.</td>\n",
       "      <td>Message-ID: &lt;358967.1075848338654.JavaMail.eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>baughman-d/power/cinergy_index/48.</td>\n",
       "      <td>Message-ID: &lt;26917144.1075848338677.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>baughman-d/power/cinergy_index/49.</td>\n",
       "      <td>Message-ID: &lt;15598486.1075848338699.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                file  \\\n",
       "0           0  baughman-d/power/cinergy_index/45.   \n",
       "1           1  baughman-d/power/cinergy_index/46.   \n",
       "2           2  baughman-d/power/cinergy_index/47.   \n",
       "3           3  baughman-d/power/cinergy_index/48.   \n",
       "4           4  baughman-d/power/cinergy_index/49.   \n",
       "\n",
       "                                             message  \n",
       "0  Message-ID: <11686348.1075848338607.JavaMail.e...  \n",
       "1  Message-ID: <18375400.1075848338630.JavaMail.e...  \n",
       "2  Message-ID: <358967.1075848338654.JavaMail.eva...  \n",
       "3  Message-ID: <26917144.1075848338677.JavaMail.e...  \n",
       "4  Message-ID: <15598486.1075848338699.JavaMail.e...  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(r'F:\\Muthu_2023\\Personal\\NextStep\\NLP\\NLP\\Dataset\\Email\\test_data.csv') #, skiprows=20000, nrows=8000, header=None)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "92804c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content</th>\n",
       "      <th>sent_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>baughman-d/power/cinergy_index/45.</td>\n",
       "      <td>Message-ID: &lt;11686348.1075848338607.JavaMail.e...</td>\n",
       "      <td>great talking with you.  see you the other guy...</td>\n",
       "      <td>[great talking with you, see you the other guy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>baughman-d/power/cinergy_index/46.</td>\n",
       "      <td>Message-ID: &lt;18375400.1075848338630.JavaMail.e...</td>\n",
       "      <td>the hourly indexes have been posted check out ...</td>\n",
       "      <td>[the hourly indexes have been posted check out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>baughman-d/power/cinergy_index/47.</td>\n",
       "      <td>Message-ID: &lt;358967.1075848338654.JavaMail.eva...</td>\n",
       "      <td>for our hourly daily and term indexes log on t...</td>\n",
       "      <td>[for our hourly daily and term indexes log on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>baughman-d/power/cinergy_index/48.</td>\n",
       "      <td>Message-ID: &lt;26917144.1075848338677.JavaMail.e...</td>\n",
       "      <td>for our industry coverage and hourly daily and...</td>\n",
       "      <td>[for our industry coverage and hourly daily an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>baughman-d/power/cinergy_index/49.</td>\n",
       "      <td>Message-ID: &lt;15598486.1075848338699.JavaMail.e...</td>\n",
       "      <td>attached is the form id like everyone to use f...</td>\n",
       "      <td>[attached is the form id like everyone to use ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                file  \\\n",
       "0           0  baughman-d/power/cinergy_index/45.   \n",
       "1           1  baughman-d/power/cinergy_index/46.   \n",
       "2           2  baughman-d/power/cinergy_index/47.   \n",
       "3           3  baughman-d/power/cinergy_index/48.   \n",
       "4           4  baughman-d/power/cinergy_index/49.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <11686348.1075848338607.JavaMail.e...   \n",
       "1  Message-ID: <18375400.1075848338630.JavaMail.e...   \n",
       "2  Message-ID: <358967.1075848338654.JavaMail.eva...   \n",
       "3  Message-ID: <26917144.1075848338677.JavaMail.e...   \n",
       "4  Message-ID: <15598486.1075848338699.JavaMail.e...   \n",
       "\n",
       "                                             content  \\\n",
       "0  great talking with you.  see you the other guy...   \n",
       "1  the hourly indexes have been posted check out ...   \n",
       "2  for our hourly daily and term indexes log on t...   \n",
       "3  for our industry coverage and hourly daily and...   \n",
       "4  attached is the form id like everyone to use f...   \n",
       "\n",
       "                                           sent_list  \n",
       "0  [great talking with you, see you the other guy...  \n",
       "1  [the hourly indexes have been posted check out...  \n",
       "2  [for our hourly daily and term indexes log on ...  \n",
       "3  [for our industry coverage and hourly daily an...  \n",
       "4  [attached is the form id like everyone to use ...  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = text_preprocess(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3264433a",
   "metadata": {},
   "source": [
    "**`Perplexity Calculation for bigram and trigram model`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "09fce587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcPerplexity(sentence, ngram):\n",
    "    word_list = str(sentence).split()\n",
    "    N = len(word_list)\n",
    "    ppx = []\n",
    "    if ngram == 2:\n",
    "        for i in range(N-1):\n",
    "            try:\n",
    "                ppx.append(1/(bi_dict_prob[(word_list[i], word_list[i+1])]))\n",
    "            except:\n",
    "                continue\n",
    "    elif ngram == 3:\n",
    "        for i in range(len(word_list)-2):\n",
    "            try:\n",
    "                ppx.append(1/tri_dict_prob[(word_list[i], word_list[i+1], word_list[i+2])])\n",
    "            except:\n",
    "                continue\n",
    "    if len(ppx) > 0:\n",
    "        return round(np.prod(ppx) ** (1/N),2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61673f3f",
   "metadata": {},
   "source": [
    "**`Extract sentences as separate rows from the message`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "94c3cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_exp = test_df['sent_list'].explode(['sent_list'])\n",
    "test_df_exp = test_df_exp.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f5e9bd",
   "metadata": {},
   "source": [
    "**`Calculate perplexity score for bigram and trigram model`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "37ed1629",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_exp['trigram_score'] = test_df_exp['sent_list'].apply(lambda x: CalcPerplexity(x,3))\n",
    "test_df_exp['bigram_score'] = test_df_exp['sent_list'].apply(lambda x: CalcPerplexity(x,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953805f9",
   "metadata": {},
   "source": [
    "**`Trigram model outperforms Bigram model in terms of perplexity score`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "36170d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Perplexity score Bigram Model:  inf\n",
      "Mean Perplexity score Trigram Model:  3.035378090277218\n"
     ]
    }
   ],
   "source": [
    "print('Mean Perplexity score for Bigram Model: ',test_df_exp['bigram_score'].mean())\n",
    "print('Mean Perplexity score for Trigram Model: ',test_df_exp['trigram_score'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
