{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa681b26",
   "metadata": {},
   "source": [
    "# Email Auto Fill\n",
    "- **Text Preprocessing**\n",
    "    - *Contractions, Sentence Tokenization*\n",
    "- **Basic EDA**\n",
    "    - *Word Cloud*\n",
    "- **Probabilistic Language Models**\n",
    "    - *Unigram, Bigrams, Trigrams, N-grams*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f309901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk, re, string, contractions\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import email\n",
    "from nltk.util import bigrams, trigrams\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be96ed0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      file  \\\n",
       "0           0     allen-p/_sent_mail/1.   \n",
       "1           1    allen-p/_sent_mail/10.   \n",
       "2           2   allen-p/_sent_mail/100.   \n",
       "3           3  allen-p/_sent_mail/1000.   \n",
       "4           4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...  \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...  \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...  \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...  \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'F:\\Muthu_2023\\Personal\\NextStep\\NLP\\NLP\\Dataset\\Email\\email_truncated.csv')\n",
    "# df = pd.read_csv(r'E:\\Nextstep\\NLP\\Dataset\\Email\\email_truncated.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed8925a",
   "metadata": {},
   "source": [
    "**Text Preprocessing:**\n",
    "- **`Using email library, extract body from the complete message`**\n",
    "- **`Remove all new line characters`**\n",
    "- **`Remove all non alpha numeric characters`**\n",
    "- **`Strip the and lower case the text`**\n",
    "- **`Apply contractions`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c9312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMessage(message):\n",
    "    e = email.message_from_string(message)\n",
    "    return e.get_payload().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f35122d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     here is our forecast\n",
       "1        traveling to have a business meeting takes the...\n",
       "2                              test successful.  way to go\n",
       "3        randy   can you send me a schedule of the sala...\n",
       "4                        let us shoot for tuesday at 1145.\n",
       "                               ...                        \n",
       "19995    don  i have extended your trial to tradersnews...\n",
       "19996    were pleased to announce two new price reporte...\n",
       "19997    for the tradersnews indexes and more industry ...\n",
       "19998    sounds great  keep up the good work power god....\n",
       "19999    great talking with you.  see you the other guy...\n",
       "Name: content, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'] = df['message'].apply(extractMessage)\n",
    "df['content'] = df['content'].str.replace(\"\\n\", \" \")\n",
    "df['content'] = df['content'].apply(lambda x: re.sub(\"[^a-zA-Z0-9 \\.]\", \"\", x))\n",
    "df['content'] = df['content'].str.strip().str.lower()\n",
    "df['content'] = df['content'].apply(lambda x: contractions.fix(x))\n",
    "df['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3c82e",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25015aea",
   "metadata": {},
   "source": [
    "**`Histogram plot for number of words in a message`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d73e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['content'].apply(lambda x: len(x)), bins=1000)\n",
    "plt.xlim(0,10000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736beb0c",
   "metadata": {},
   "source": [
    "**`Create a column with sentences as list elements for each message in main dataframe`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51971312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenization(text):\n",
    "    sentence_list = sent_tokenize(text)\n",
    "    transformed_sent = []\n",
    "    for sentence in sentence_list:\n",
    "        sentence = (re.sub(\"[^a-zA-Z0-9 ]\", \"\", sentence))\n",
    "        words = []\n",
    "        for word in sentence.split():\n",
    "            if len(word) < 20 and word.strip().isalpha():\n",
    "                words.append(word.strip())\n",
    "        if len(words) > 0:\n",
    "            transformed_sent.append(\" \".join(words))\n",
    "    return transformed_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "999347ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sent_list'] = df['content'].apply(sentence_tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064adb5f",
   "metadata": {},
   "source": [
    "**`Generate Word Count Vector for the complete corpus`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3b03828",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for sent_tokens in df['sent_list']:\n",
    "    for sent in sent_tokens:\n",
    "        for word in sent.split():\n",
    "            word = word.replace(\".\", \"\").strip()\n",
    "            if word in d:\n",
    "                d[word] += 1\n",
    "            else:\n",
    "                d[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205409fd",
   "metadata": {},
   "source": [
    "**`Sort Top N words by total count in the corpus `**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8a07391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 194347),\n",
       " ('to', 140013),\n",
       " ('and', 87514),\n",
       " ('a', 79911),\n",
       " ('of', 72795),\n",
       " ('in', 61234),\n",
       " ('you', 54237),\n",
       " ('for', 52873),\n",
       " ('is', 50794),\n",
       " ('on', 47504),\n",
       " ('i', 39791),\n",
       " ('this', 34549),\n",
       " ('that', 34048),\n",
       " ('not', 29304),\n",
       " ('be', 29176),\n",
       " ('will', 28690),\n",
       " ('from', 28524),\n",
       " ('with', 27117),\n",
       " ('at', 26695),\n",
       " ('have', 26266)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(d.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a01b28",
   "metadata": {},
   "source": [
    "***All Top20 words are Stopwords***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cf920",
   "metadata": {},
   "source": [
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243bfa67",
   "metadata": {},
   "source": [
    "**`Build Word cloud from the email body texts`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac8e0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "555eef11",
   "metadata": {},
   "source": [
    "# Bigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ecffbe",
   "metadata": {},
   "source": [
    "**`Generate bigram dictionary with frequency of occurence in {(currentword, nextword): freq}`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7395ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_dict = {}\n",
    "for message in df['sent_list']:\n",
    "    for sentence in message:\n",
    "        for words in bigrams(sentence.split()):\n",
    "            if words in bi_dict:\n",
    "                bi_dict[words] += 1\n",
    "            else:\n",
    "                bi_dict[words] = 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "017ba8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_dict_prob = {}\n",
    "for w1, w2 in bi_dict:\n",
    "    bi_dict_prob[(w1, w2)] = bi_dict[(w1, w2)] / d[w1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff778d3",
   "metadata": {},
   "source": [
    "**`Sort the dictinary based on key and values`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "482e9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_dict_sorted = dict(sorted(bi_dict_prob.items(), key=lambda x: (x[0][0], x[1]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b4df2555-5aa1-409c-98f9-427f0e8b7cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626705"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bi_dict_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533bc49e",
   "metadata": {},
   "source": [
    "**`Create data frame from the dictinary for easier processing`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cb04327f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zypfje</td>\n",
       "      <td>baughmandon</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zy</td>\n",
       "      <td>for</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zwiebel</td>\n",
       "      <td>calls</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zwiebel</td>\n",
       "      <td>and</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zwerneman</td>\n",
       "      <td>jazztotalzonecom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0           level_1  Count\n",
       "0     zypfje       baughmandon    1.0\n",
       "1         zy               for    1.0\n",
       "2    zwiebel             calls    0.5\n",
       "3    zwiebel               and    0.5\n",
       "4  zwerneman  jazztotalzonecom    1.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_df = pd.DataFrame(data = bi_dict_sorted.values(), columns=['Count'], index=bi_dict_sorted.keys())\n",
    "bi_df.reset_index(inplace=True)\n",
    "bi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73e902c",
   "metadata": {},
   "source": [
    "**`Extract top N Next words in list for each Current word`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "be67efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "filtered_bi = bi_df.drop('Count', axis=1).groupby('level_0').head(N)\n",
    "filtered_bi = filtered_bi.groupby('level_0')['level_1'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5b22c7",
   "metadata": {},
   "source": [
    "**`Transform dataframe to dictionary with key as current word and values as N next words`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "475815cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bi_dict = dict()\n",
    "for i in range(len(filtered_bi)):\n",
    "    filtered_bi_dict[filtered_bi['level_0'].iloc[i]] = filtered_bi['level_1'].iloc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9665b",
   "metadata": {},
   "source": [
    "**`Derive the next N words for the current word from the dictionary`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bb77d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nextwords(Queryword, filtered_bi_dict):\n",
    "    if Queryword.lower() in filtered_bi_dict:\n",
    "        return filtered_bi_dict[Queryword.lower()]\n",
    "    else:\n",
    "        return \"Word not exist in dictionary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2e8ae35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am', 'have', 'will']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('I', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d359a7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to', 'about', 'much']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('how', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "80ba0755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'be', 'get']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('to', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0f7ec631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['following', 'last', 'new']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('the', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2d6244e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'have', 'rank']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('they', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "74883326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'be', 'do']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('can', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6dfd24",
   "metadata": {},
   "source": [
    "**`Generate the next M sequence words for the current word`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2719865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron north america corp from the following the following the following\n"
     ]
    }
   ],
   "source": [
    "M = 10\n",
    "CurrWord = 'Enron'\n",
    "word_list = [CurrWord]\n",
    "for x in range(M):    \n",
    "    CurrWord = get_nextwords(CurrWord, filtered_bi_dict)[0]\n",
    "    word_list.append(CurrWord)\n",
    "print(\" \".join(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e604f4",
   "metadata": {},
   "source": [
    "# Trigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc43c3",
   "metadata": {},
   "source": [
    "**`Generate conditional probability of trigram`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8e742620",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_dict = {}\n",
    "tri_dict_prob = {}\n",
    "for message in df['sent_list']:\n",
    "    for sentence in message:\n",
    "        for words in trigrams(sentence.split()):\n",
    "            if words in tri_dict:\n",
    "                tri_dict[words] += 1\n",
    "            else:\n",
    "                tri_dict[words] = 1\n",
    "\n",
    "for words in tri_dict:\n",
    "    currwords = words[:-1]\n",
    "    tri_dict_prob[words] = tri_dict[words] / bi_dict[currwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "587a373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_dict_sort = sorted(tri_dict_prob.items(), key = (lambda x: (x[0][:2], x[1])), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb10fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_dict_df = pd.DataFrame(data = tri_dict_sort.values(), index = tri_dict_sort.keys())\n",
    "tri_dict_df.head()\n",
    "tri_dict_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
