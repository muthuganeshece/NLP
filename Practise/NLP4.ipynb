{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa681b26",
   "metadata": {},
   "source": [
    "# Email Auto Fill\n",
    "- **Text Preprocessing**\n",
    "    - *Contractions, Sentence Tokenization*\n",
    "- **Basic EDA**\n",
    "    - *Word Cloud*\n",
    "- **Probabilistic Language Models**\n",
    "    - *Unigram, Bigrams, Trigrams, N-grams*\n",
    "- **Model Evaluation**\n",
    "    - *Perplexity* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f309901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk, re, string, contractions\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import email\n",
    "from nltk.util import bigrams, trigrams\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be96ed0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      file  \\\n",
       "0           0     allen-p/_sent_mail/1.   \n",
       "1           1    allen-p/_sent_mail/10.   \n",
       "2           2   allen-p/_sent_mail/100.   \n",
       "3           3  allen-p/_sent_mail/1000.   \n",
       "4           4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...  \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...  \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...  \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...  \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'F:\\Muthu_2023\\Personal\\NextStep\\NLP\\NLP\\Dataset\\Email\\email_truncated.csv')\n",
    "# df = pd.read_csv(r'E:\\Nextstep\\NLP\\Dataset\\Email\\email_truncated.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed8925a",
   "metadata": {},
   "source": [
    "**Text Preprocessing:**\n",
    "- **`Using email library, extract body from the complete message`**\n",
    "- **`Remove all new line characters`**\n",
    "- **`Remove all non alpha numeric characters`**\n",
    "- **`Strip the and lower case the text`**\n",
    "- **`Apply contractions`**\n",
    "- **`Create a column with sentences as list elements for each message in main dataframe`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f8fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMessage(message):\n",
    "    e = email.message_from_string(message)\n",
    "    return e.get_payload().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd648d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenization(text):\n",
    "    sentence_list = sent_tokenize(text)\n",
    "    transformed_sent = []\n",
    "    for sentence in sentence_list:\n",
    "        sentence = (re.sub(\"[^a-zA-Z0-9 ]\", \"\", sentence))\n",
    "        words = []\n",
    "        for word in sentence.split():\n",
    "            if len(word) < 20 and word.strip().isalpha():\n",
    "                words.append(word.strip())\n",
    "        if len(words) > 0:\n",
    "            transformed_sent.append(\" \".join(words))\n",
    "    return transformed_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f35122d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     here is our forecast\n",
       "1        traveling to have a business meeting takes the...\n",
       "2                              test successful.  way to go\n",
       "3        randy   can you send me a schedule of the sala...\n",
       "4                        let us shoot for tuesday at 1145.\n",
       "                               ...                        \n",
       "19995    don  i have extended your trial to tradersnews...\n",
       "19996    were pleased to announce two new price reporte...\n",
       "19997    for the tradersnews indexes and more industry ...\n",
       "19998    sounds great  keep up the good work power god....\n",
       "19999    great talking with you.  see you the other guy...\n",
       "Name: content, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_preprocess(local_df)\n",
    "    local_df['content'] = local_df['message'].apply(extractMessage)\n",
    "    local_df['content'] = local_df['content'].str.replace(\"\\n\", \" \")\n",
    "    local_df['content'] = local_df['content'].apply(lambda x: re.sub(\"[^a-zA-Z0-9 \\.]\", \"\", x))\n",
    "    local_df['content'] = local_df['content'].str.strip().str.lower()\n",
    "    local_df['content'] = local_df['content'].apply(lambda x: contractions.fix(x))\n",
    "    local_df['sent_list'] = local_df['content'].apply(sentence_tokenization)\n",
    "    return local_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = text_preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3c82e",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25015aea",
   "metadata": {},
   "source": [
    "**`Histogram plot for number of words in a message`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d73e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['content'].apply(lambda x: len(x)), bins=1000)\n",
    "plt.xlim(0,10000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa7a2e3",
   "metadata": {},
   "source": [
    "**`Generate Word Count Vector for the complete corpus`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af5ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for sent_tokens in df['sent_list']:\n",
    "    for sent in sent_tokens:\n",
    "        for word in sent.split():\n",
    "            word = word.replace(\".\", \"\").strip()\n",
    "            if word in d:\n",
    "                d[word] += 1\n",
    "            else:\n",
    "                d[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205409fd",
   "metadata": {},
   "source": [
    "**`Sort Top N words by total count in the corpus `**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8a07391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 194347),\n",
       " ('to', 140013),\n",
       " ('and', 87514),\n",
       " ('a', 79911),\n",
       " ('of', 72795),\n",
       " ('in', 61234),\n",
       " ('you', 54237),\n",
       " ('for', 52873),\n",
       " ('is', 50794),\n",
       " ('on', 47504),\n",
       " ('i', 39791),\n",
       " ('this', 34549),\n",
       " ('that', 34048),\n",
       " ('not', 29304),\n",
       " ('be', 29176),\n",
       " ('will', 28690),\n",
       " ('from', 28524),\n",
       " ('with', 27117),\n",
       " ('at', 26695),\n",
       " ('have', 26266)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(d.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a01b28",
   "metadata": {},
   "source": [
    "***All Top20 words are Stopwords***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cf920",
   "metadata": {},
   "source": [
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243bfa67",
   "metadata": {},
   "source": [
    "**`Build Word cloud from the email body texts`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac8e0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "555eef11",
   "metadata": {},
   "source": [
    "# Bigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ecffbe",
   "metadata": {},
   "source": [
    "**`Generate bigram dictionary with frequency of occurence in {(currentword, nextword): freq}`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7395ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_dict = {}\n",
    "for message in df['sent_list']:\n",
    "    for sentence in message:\n",
    "        for words in bigrams(sentence.split()):\n",
    "            if words in bi_dict:\n",
    "                bi_dict[words] += 1\n",
    "            else:\n",
    "                bi_dict[words] = 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c1f98242",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_dict_prob = {}\n",
    "for w1, w2 in bi_dict:\n",
    "    bi_dict_prob[(w1, w2)] = bi_dict[(w1, w2)] / d[w1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff778d3",
   "metadata": {},
   "source": [
    "**`Sort the dictinary based on key and values`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a9077e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_dict_sorted = dict(sorted(bi_dict_prob.items(), key=lambda x: (x[0][0], x[1]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b4df2555-5aa1-409c-98f9-427f0e8b7cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626705"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bi_dict_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b535d6",
   "metadata": {},
   "source": [
    "**`Create data frame from the dictinary for easier processing`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e85c8d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zypfje</td>\n",
       "      <td>baughmandon</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zy</td>\n",
       "      <td>for</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zwiebel</td>\n",
       "      <td>calls</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zwiebel</td>\n",
       "      <td>and</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zwerneman</td>\n",
       "      <td>jazztotalzonecom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0           level_1  Count\n",
       "0     zypfje       baughmandon    1.0\n",
       "1         zy               for    1.0\n",
       "2    zwiebel             calls    0.5\n",
       "3    zwiebel               and    0.5\n",
       "4  zwerneman  jazztotalzonecom    1.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_df = pd.DataFrame(data = bi_dict_sorted.values(), columns=['Count'], index=bi_dict_sorted.keys())\n",
    "bi_df.reset_index(inplace=True)\n",
    "bi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5752f69f",
   "metadata": {},
   "source": [
    "**`Extract top N Next words in list for each Current word`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fe738d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "filtered_bi = bi_df.drop('Count', axis=1).groupby('level_0').head(N)\n",
    "filtered_bi = filtered_bi.groupby('level_0')['level_1'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a53c4",
   "metadata": {},
   "source": [
    "**`Transform dataframe to dictionary with key as current word and values as N next words`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f8422f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bi_dict = dict()\n",
    "for i in range(len(filtered_bi)):\n",
    "    filtered_bi_dict[filtered_bi['level_0'].iloc[i]] = filtered_bi['level_1'].iloc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b7430a",
   "metadata": {},
   "source": [
    "**`Derive the next N words for the current word from the dictionary`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ea9a05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nextwords(Queryword, in_dict):\n",
    "    if Queryword.lower() in in_dict:\n",
    "        return in_dict[Queryword.lower()]\n",
    "    else:\n",
    "        return \"Word not exist in dictionary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "636c7357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am', 'have', 'will']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('I', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ada568e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to', 'about', 'much']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('how', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "20d27ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'be', 'get']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('to', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "08e591dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['following', 'last', 'new']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('the', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "057bc5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'have', 'rank']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('they', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cc153d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'be', 'do']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords('can', filtered_bi_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4f735",
   "metadata": {},
   "source": [
    "**`Generate the next M sequence words for the current word`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f7d52d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron north america corp from the following the following the following\n"
     ]
    }
   ],
   "source": [
    "M = 10\n",
    "CurrWord = 'Enron'\n",
    "word_list = [CurrWord]\n",
    "for x in range(M):    \n",
    "    CurrWord = get_nextwords(CurrWord, filtered_bi_dict)[0]\n",
    "    word_list.append(CurrWord)\n",
    "print(\" \".join(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a0af5",
   "metadata": {},
   "source": [
    "# Trigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afbeba",
   "metadata": {},
   "source": [
    "**`Generate conditional probability of trigram`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3b4efe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_dict = {}\n",
    "tri_dict_prob = {}\n",
    "for message in df['sent_list']:\n",
    "    for sentence in message:\n",
    "        for words in trigrams(sentence.split()):\n",
    "            if words in tri_dict:\n",
    "                tri_dict[words] += 1\n",
    "            else:\n",
    "                tri_dict[words] = 1\n",
    "\n",
    "for words in tri_dict:\n",
    "    currwords = words[:-1]\n",
    "    tri_dict_prob[words] = tri_dict[words] / bi_dict[currwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f77d90",
   "metadata": {},
   "source": [
    "**`Group Sort the dictionary based on the maximum likelyhood probability and create dataframe`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0358232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_dict_sort = dict(sorted(tri_dict_prob.items(), key = (lambda x: (x[0][:2], x[1])), reverse=True))\n",
    "tri_dict_df = pd.DataFrame(data = tri_dict_sort.values(), columns=['Count'], index=tri_dict_sort.keys())\n",
    "tri_dict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe6882",
   "metadata": {},
   "source": [
    "**`Extract Top N next words for each bigrams`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d2b297c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_dict_df_filtered = tri_dict_df.drop('Count', axis=1).reset_index().groupby(['level_0', 'level_1']).head(3)\n",
    "tri_dict_df_filtered = tri_dict_df_filtered.groupby(['level_0', 'level_1'])['level_2'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef6d421",
   "metadata": {},
   "source": [
    "**`Convert DF to dictionary with currwords as index and next N words list as value`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "94d78644",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tri_dict = dict()\n",
    "for i in range(len(tri_dict_df_filtered)):\n",
    "    currwords = (tri_dict_df_filtered['level_0'].iloc[i], tri_dict_df_filtered['level_1'].iloc[i])\n",
    "    filtered_tri_dict[currwords] = tri_dict_df_filtered['level_2'].iloc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2520ee3",
   "metadata": {},
   "source": [
    "**`Get next words list for the given bigram`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "79566ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nextwords_tri(Query, in_dict):\n",
    "    words = tuple(Query.lower().split())\n",
    "    if words in in_dict:\n",
    "        return in_dict[words]\n",
    "    else:\n",
    "        return \"Words not exist in dictionary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06225ac",
   "metadata": {},
   "source": [
    "**`Example results for random bigram`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7c959d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not', 'going', 'sure']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords_tri('i am', filtered_tri_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "750685fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['been', 'not', 'a']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords_tri('i have', filtered_tri_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b8934a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'the', 'an']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nextwords_tri('season with', filtered_tri_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2da534",
   "metadata": {},
   "source": [
    "**`Text Generation from the trigram model`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3a472efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words_tri(seed, word_dict, seq):\n",
    "    word_query = seed.lower().split()\n",
    "    for x in range(seq):\n",
    "        nxtword = get_nextwords_tri(\" \".join(word_query[x:]), word_dict)\n",
    "        word_query.append(nxtword[0])\n",
    "    return \" \".join(word_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2de5b1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am not sure what you think of the season with a sore knee and is expected to play with his sore shoulder and neck W W'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_words_tri('I am', filtered_tri_dict, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0bfc5b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how are you going to be a good idea to keep the tradition and organize a thanksgiving dinner i can do it all to brunch swcc am'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_words_tri('how are', filtered_tri_dict, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bde8c77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i heard that you are not the intended recipient or authorized to receive for the year they rank in fantasy points allowed to the opposing qb for'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_words_tri('I heard', filtered_tri_dict, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "25559d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can we meet at the end of the season with a sore knee and is expected to play with his sore shoulder and neck W W W'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_words_tri('can we', filtered_tri_dict, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25045c77",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ef158",
   "metadata": {},
   "source": [
    "**`Model Perplexity score calcuation`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f31ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
